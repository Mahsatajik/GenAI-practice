{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tce3stUlHN0L"
   },
   "source": [
    "### [Blog Post](https://storm-jacket-4ec.notion.site/1dbd34e9912680ed826ccd1d5a991792?pvs=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:57:28.036529Z",
     "iopub.status.busy": "2025-04-20T18:57:28.036233Z",
     "iopub.status.idle": "2025-04-20T18:58:26.986407Z",
     "shell.execute_reply": "2025-04-20T18:58:26.985462Z",
     "shell.execute_reply.started": "2025-04-20T18:57:28.036506Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping kfp as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab-lsp 3.10.2 requires jupyterlab<4.0.0a0,>=3.1.0, which is not installed.\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\n",
      "google-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\n",
      "pandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "google-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install -qU \"google-genai==1.7.0\" \"chromadb==0.6.3\"\n",
    "!pip uninstall -qqy jupyterlab kfp\n",
    "!pip install -qU \\\n",
    "    google-genai==1.7.0 \\\n",
    "    chromadb==0.6.3 \\\n",
    "    langchain \\\n",
    "    tenacity \\\n",
    "    rapidfuzz \\\n",
    "    rouge-score \\\n",
    "    scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:58:26.987767Z",
     "iopub.status.busy": "2025-04-20T18:58:26.987503Z",
     "iopub.status.idle": "2025-04-20T18:58:50.552093Z",
     "shell.execute_reply": "2025-04-20T18:58:50.550928Z",
     "shell.execute_reply.started": "2025-04-20T18:58:26.987744Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.3.31-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.54)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-prebuilt<0.2,>=0.1.8 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.61-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (0.3.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (4.13.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (2.11.3)\n",
      "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
      "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
      "Downloading langgraph-0.3.31-py3-none-any.whl (145 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.2/145.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langgraph_checkpoint-2.0.24-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
      "Downloading langgraph_sdk-0.1.61-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
      "Successfully installed langgraph-0.3.31 langgraph-checkpoint-2.0.24 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.61 ormsgpack-1.9.1\n",
      "Collecting gradio==5.25.2\n",
      "  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (22.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (4.9.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (0.115.12)\n",
      "Collecting ffmpy (from gradio==5.25.2)\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.8.0 (from gradio==5.25.2)\n",
      "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio==5.25.2)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (0.30.2)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (3.10.15)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (11.1.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (2.11.3)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (0.25.1)\n",
      "Collecting python-multipart>=0.0.18 (from gradio==5.25.2)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (6.0.2)\n",
      "Collecting ruff>=0.9.3 (from gradio==5.25.2)\n",
      "  Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio==5.25.2)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio==5.25.2)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (0.46.2)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio==5.25.2)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (4.13.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.25.2) (0.34.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio==5.25.2) (2025.3.2)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio==5.25.2) (14.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio==5.25.2) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio==5.25.2) (1.3.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==5.25.2) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==5.25.2) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==5.25.2) (0.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio==5.25.2) (3.18.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio==5.25.2) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio==5.25.2) (4.67.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio==5.25.2) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio==5.25.2) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio==5.25.2) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio==5.25.2) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio==5.25.2) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio==5.25.2) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.25.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.25.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.25.2) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio==5.25.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio==5.25.2) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio==5.25.2) (0.4.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.25.2) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.25.2) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.25.2) (14.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio==5.25.2) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.25.2) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.25.2) (2.19.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio==5.25.2) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio==5.25.2) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.0->gradio==5.25.2) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.0->gradio==5.25.2) (2024.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio==5.25.2) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio==5.25.2) (2.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.0->gradio==5.25.2) (2024.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==5.25.2) (0.1.2)\n",
      "Downloading gradio-5.25.2-py3-none-any.whl (46.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Installing collected packages: tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, safehttpx, gradio-client, gradio\n",
      "Successfully installed ffmpy-0.5.0 gradio-5.25.2 gradio-client-1.8.0 groovy-0.1.2 python-multipart-0.0.20 ruff-0.11.6 safehttpx-0.1.6 semantic-version-2.10.0 tomlkit-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -q \"google-genai==1.7.0\"\n",
    "!pip install rouge-score -q\n",
    "!pip install langgraph\n",
    "!pip install gradio==5.25.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:59:02.941979Z",
     "iopub.status.busy": "2025-04-20T18:59:02.941666Z",
     "iopub.status.idle": "2025-04-20T18:59:02.946216Z",
     "shell.execute_reply": "2025-04-20T18:59:02.945312Z",
     "shell.execute_reply.started": "2025-04-20T18:59:02.941954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CHROMA_DB_PATH = '/kaggle/working/chromadb_2_sample_v11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:59:06.106079Z",
     "iopub.status.busy": "2025-04-20T18:59:06.105773Z",
     "iopub.status.idle": "2025-04-20T19:00:37.918048Z",
     "shell.execute_reply": "2025-04-20T19:00:37.916698Z",
     "shell.execute_reply.started": "2025-04-20T18:59:06.106056Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API client initialized successfully.\n",
      "Loading test data...\n",
      "Test data loaded: 2 samples.\n",
      "Running LangGraph pipeline...\n",
      "Building LangGraph workflow...\n",
      "✅ Workflow built with all nodes.\n",
      "Starting summarization step...\n",
      "Loading dataset...\n",
      "Dataset loaded: 799 training, 200 test samples.\n",
      "Input 1 (length: 7898):  \n",
      "Name:  ___                   Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:   ...\n",
      "Warning: Input 1 may contain excessive placeholders or be empty.\n",
      "Input 2 (length: 9293):  \n",
      "Name:  ___                    Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:  ...\n",
      "Warning: Input 2 may contain excessive placeholders or be empty.\n",
      "input data length: 1\n",
      "Prepared input data for fine-tuning.\n",
      "Generating summary for text (length: 7898)...\n",
      "model_id: tunedModels/summarization-model-9zeddx1lwavq\n",
      "API Finish Reason: STOP\n",
      "Summary generated (length: 3345): ## Discharge Summary for [Patient Name]\n",
      "\n",
      "**Admission:** [Date]\n",
      "**Discharge:** [Date]\n",
      "**DOB:** [Date]...\n",
      "Generating summary for text (length: 9293)...\n",
      "model_id: tunedModels/summarization-model-9zeddx1lwavq\n",
      "API Finish Reason: STOP\n",
      "Summary generated (length: 2731): ## Clinical Discharge Summary\n",
      "\n",
      "**Patient Information:**\n",
      "- **Name:** Redacted\n",
      "- **Date of Birth:** Re...\n",
      "✅ Generated 2 valid summaries.\n",
      "Sample summaries: ['## Discharge Summary for [Patient Name]\\n\\n**Admission:** [Date]\\n**Discharge:** [Date]\\n**DOB:** [Date]', '## Clinical Discharge Summary\\n\\n**Patient Information:**\\n- **Name:** Redacted\\n- **Date of Birth:** Re']\n",
      "Starting database storage step...\n",
      "✅ Database initialized at /kaggle/working/clinical_data.db.\n",
      "Stored summary (ID: deaca831-754e-442b-b5df-774a2b79a24f, summary length: 3345).\n",
      "Stored summary (ID: c5653c21-19b0-4bed-8ce1-cd5917ad7e3b, summary length: 2731).\n",
      "✅ Stored 2 summaries in database.\n",
      "Starting criteria processing step...\n",
      "Found 1 CSV files in /kaggle/input/clinical-trial-sample.\n",
      "Converted /kaggle/input/clinical-trial-sample/HBP.csv to /kaggle/working/HBP.json.\n",
      "✅ Processed HBP: 8 prompts written to /kaggle/working/Criteria_based_Prompts/HBP.\n",
      "✅ Generated 8 criteria prompts.\n",
      "✅ Found 1 trial names: ['HBP']\n",
      "Starting chunking and embedding step...\n",
      "✅ Persistent ChromaDB client initialized at /kaggle/working/chromadb_2_sample_v11.\n",
      "Generated 20 chunks from 2 summaries.\n",
      "Sample chunks: ['## Discharge Summary for [Patient Name]\\n\\n**Admission:** [Date]\\n**Discharge:** [Date]\\n**DOB:** [Date]\\n**Sex:** Female\\n**Service:** Surgery\\n**Attending:** [Redacted]\\n\\n**Allergies:**\\n- Sulfonamides\\n- Codeine\\n- Bactrim\\n\\n**Chief Complaint:**\\n- Abdominal pain and vomiting\\n\\n**Major Surgical Procedure:**\\n- Exploratory laparotomy, lysis of adhesions, small bowel resection with enteroenterostomy.', '**History of Present Illness:**\\n- Patient presented with cramping abdominal pain, nausea, and bilious emesis. She experienced multiple episodes of vomiting and diarrhea, leading to an ED visit. No history of similar pain or small bowel obstruction.\\n\\n**Past Medical History:**\\n- Carcinoid tumor (status post right lung resection)\\n- Vitamin B12 deficiency\\n- Depression\\n- Hyperlipidemia']\n",
      "Sample chunk IDs: ['deaca831-754e-442b-b5df-774a2b79a24f_0', 'deaca831-754e-442b-b5df-774a2b79a24f_1']\n",
      "Collection does not exist: Collection mimic_iv_summary_chunks_trial does not exist.. Creating new collection 'mimic_iv_summary_chunks_trial'...\n",
      "✅ Collection created successfully.\n",
      "Generated 20 embeddings with dimension 768\n",
      "✅ Stored 20 chunks in ChromaDB collection 'mimic_iv_summary_chunks_trial'.\n",
      "✅ Verified collection exists with 20 chunks.\n",
      "✅ Stored 20 chunk IDs.\n",
      "Starting eligibility checking step...\n",
      "✅ ChromaDB collection loaded with 20 chunks.\n",
      "Generated 1 embeddings with dimension 768\n",
      "Retrieved 5 chunks for criterion 'HBP-Inclusion_1'.\n",
      "✅ Evaluated eligibility for 'HBP-Inclusion_1': 2 results.\n",
      "Generated 1 embeddings with dimension 768\n",
      "Retrieved 5 chunks for criterion 'HBP-Inclusion_2'.\n",
      "✅ Evaluated eligibility for 'HBP-Inclusion_2': 2 results.\n",
      "Generated 1 embeddings with dimension 768\n",
      "Retrieved 5 chunks for criterion 'HBP-Exclusion_1'.\n",
      "⚠️ Missing result for summary ID deaca831-754e-442b-b5df-774a2b79a24f in criterion 'HBP-Exclusion_1'.\n",
      "✅ Evaluated eligibility for 'HBP-Exclusion_1': 1 results.\n",
      "Generated 1 embeddings with dimension 768\n",
      "Retrieved 5 chunks for criterion 'HBP-Exclusion_2'.\n",
      "⚠️ Missing result for summary ID deaca831-754e-442b-b5df-774a2b79a24f in criterion 'HBP-Exclusion_2'.\n",
      "✅ Evaluated eligibility for 'HBP-Exclusion_2': 1 results.\n",
      "Generated 1 embeddings with dimension 768\n",
      "Retrieved 5 chunks for criterion 'HBP-Exclusion_3'.\n",
      "✅ Evaluated eligibility for 'HBP-Exclusion_3': 2 results.\n",
      "Generated 1 embeddings with dimension 768\n",
      "Retrieved 5 chunks for criterion 'HBP-Exclusion_4'.\n",
      "✅ Evaluated eligibility for 'HBP-Exclusion_4': 2 results.\n",
      "Generated 1 embeddings with dimension 768\n",
      "Retrieved 5 chunks for criterion 'HBP-Exclusion_5'.\n",
      "✅ Evaluated eligibility for 'HBP-Exclusion_5': 2 results.\n",
      "Generated 1 embeddings with dimension 768\n",
      "Retrieved 5 chunks for criterion 'HBP-Exclusion_6'.\n",
      "✅ Evaluated eligibility for 'HBP-Exclusion_6': 2 results.\n",
      "✅ Generated 16 eligibility results.\n",
      "Starting evaluation step...\n",
      "✅ ChromaDB collection loaded with 20 chunks.\n",
      "Processing criterion 'HBP-Inclusion_1'...\n",
      "✅ Saved: /kaggle/working/evaluation_results/HBP-Inclusion_1_output_reverse_RAG_test.csv\n",
      "Processing criterion 'HBP-Inclusion_2'...\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "✅ Saved: /kaggle/working/evaluation_results/HBP-Inclusion_2_output_reverse_RAG_test.csv\n",
      "Processing criterion 'HBP-Exclusion_1'...\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "✅ Saved: /kaggle/working/evaluation_results/HBP-Exclusion_1_output_reverse_RAG_test.csv\n",
      "Processing criterion 'HBP-Exclusion_2'...\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "✅ Saved: /kaggle/working/evaluation_results/HBP-Exclusion_2_output_reverse_RAG_test.csv\n",
      "Processing criterion 'HBP-Exclusion_3'...\n",
      "✅ Saved: /kaggle/working/evaluation_results/HBP-Exclusion_3_output_reverse_RAG_test.csv\n",
      "Processing criterion 'HBP-Exclusion_4'...\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "✅ Saved: /kaggle/working/evaluation_results/HBP-Exclusion_4_output_reverse_RAG_test.csv\n",
      "Processing criterion 'HBP-Exclusion_5'...\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "Generated 1 embeddings with dimension 768\n",
      "✅ Saved: /kaggle/working/evaluation_results/HBP-Exclusion_5_output_reverse_RAG_test.csv\n",
      "Processing criterion 'HBP-Exclusion_6'...\n",
      "✅ Saved: /kaggle/working/evaluation_results/HBP-Exclusion_6_output_reverse_RAG_test.csv\n",
      "✅ Saved consolidated results: /kaggle/working/evaluation_results/all_results.csv\n",
      "✅ Generated 16 evaluation results.\n",
      "\n",
      "Pipeline Result:\n",
      "Input Texts: 2\n",
      "Summaries: 2\n",
      "Summary IDs: 2\n",
      "Criteria Prompts: 8\n",
      "Chunk IDs: 20\n",
      "Eligibility Results: 16\n",
      "Evaluation Results: 16\n",
      "\n",
      "Sample 1:\n",
      "Input (first 100 chars):  \n",
      "Name:  ___                   Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:   ...\n",
      "Summary (first 200 chars): ## Discharge Summary for [Patient Name]\n",
      "\n",
      "**Admission:** [Date]\n",
      "**Discharge:** [Date]\n",
      "**DOB:** [Date]\n",
      "**Sex:** Female\n",
      "**Service:** Surgery\n",
      "**Attending:** [Redacted]\n",
      "\n",
      "**Allergies:**\n",
      "- Sulfonamides\n",
      "- Cod...\n",
      "Summary ID: deaca831-754e-442b-b5df-774a2b79a24f\n",
      "\n",
      "Sample 2:\n",
      "Input (first 100 chars):  \n",
      "Name:  ___                    Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:  ...\n",
      "Summary (first 200 chars): ## Clinical Discharge Summary\n",
      "\n",
      "**Patient Information:**\n",
      "- **Name:** Redacted\n",
      "- **Date of Birth:** Redacted\n",
      "- **Sex:** Male\n",
      "- **Service:** Medicine\n",
      "- **Admission Date:** Redacted\n",
      "- **Discharge Date:** ...\n",
      "Summary ID: c5653c21-19b0-4bed-8ce1-cd5917ad7e3b\n",
      "\n",
      "Sample Criteria Prompts:\n",
      "Prompt 1:\n",
      "Trial Name: HBP\n",
      "Criteria Name: HBP-Inclusion_1\n",
      "Text: Patient has a current diagnosis of hypertension or documented blood pressures exceeding 150/90 mmHg.\n",
      "Extractable Lexicons: ['hypertension', 'high blood pressure', 'HTN', 'BP 150/90', '160/100 mmHg']\n",
      "Prompt 2:\n",
      "Trial Name: HBP\n",
      "Criteria Name: HBP-Inclusion_2\n",
      "Text: Patient's most recent systolic blood pressure was 150 mmHg or greater.\n",
      "Extractable Lexicons: ['systolic blood pressure', 'SBP', 'BP 150/90', '160/100 mmHg']\n",
      "\n",
      "Sample Chunks:\n",
      "Chunk ID: deaca831-754e-442b-b5df-774a2b79a24f_0\n",
      "Chunk ID: deaca831-754e-442b-b5df-774a2b79a24f_1\n",
      "\n",
      "Sample Eligibility Results:\n",
      "Result 1:\n",
      "Trial Name: HBP\n",
      "Summary ID: deaca831-754e-442b-b5df-774a2b79a24f\n",
      "Criteria Name: HBP-Inclusion_1\n",
      "Eligibility: No\n",
      "Evidence: None\n",
      "Result 2:\n",
      "Trial Name: HBP\n",
      "Summary ID: c5653c21-19b0-4bed-8ce1-cd5917ad7e3b\n",
      "Criteria Name: HBP-Inclusion_1\n",
      "Eligibility: No\n",
      "Evidence: None\n",
      "Result 3:\n",
      "Trial Name: HBP\n",
      "Summary ID: deaca831-754e-442b-b5df-774a2b79a24f\n",
      "Criteria Name: HBP-Inclusion_2\n",
      "Eligibility: No\n",
      "Evidence: Vitals: Temp 96.9, HR 105, BP 108/92\n",
      "Result 4:\n",
      "Trial Name: HBP\n",
      "Summary ID: c5653c21-19b0-4bed-8ce1-cd5917ad7e3b\n",
      "Criteria Name: HBP-Inclusion_2\n",
      "Eligibility: No\n",
      "Evidence: None\n",
      "\n",
      "Sample Evaluation Results:\n",
      "Result 1:\n",
      "Trial Name: HBP\n",
      "Patient ID: deaca831-754e-442b-b5df-774a2b79a24f\n",
      "Criteria Name: HBP-Inclusion_1\n",
      "Eligibility: No\n",
      "Evidence: None\n",
      "ROUGE-1: None\n",
      "fuzz_MatchScore: None\n",
      "Result 2:\n",
      "Trial Name: HBP\n",
      "Patient ID: c5653c21-19b0-4bed-8ce1-cd5917ad7e3b\n",
      "Criteria Name: HBP-Inclusion_1\n",
      "Eligibility: No\n",
      "Evidence: None\n",
      "ROUGE-1: None\n",
      "fuzz_MatchScore: None\n",
      "Result 3:\n",
      "Trial Name: HBP\n",
      "Patient ID: deaca831-754e-442b-b5df-774a2b79a24f\n",
      "Criteria Name: HBP-Inclusion_2\n",
      "Eligibility: No\n",
      "Evidence: Vitals: Temp 96.9, HR 105, BP 108/92\n",
      "ROUGE-1: 30.0\n",
      "fuzz_MatchScore: 100.0\n",
      "Result 4:\n",
      "Trial Name: HBP\n",
      "Patient ID: c5653c21-19b0-4bed-8ce1-cd5917ad7e3b\n",
      "Criteria Name: HBP-Inclusion_2\n",
      "Eligibility: No\n",
      "Evidence: None\n",
      "ROUGE-1: None\n",
      "fuzz_MatchScore: None\n",
      "\n",
      "Verifying database contents...\n",
      "Found 2 records in database.\n",
      "Record ID: deaca831-754e-442b-b5df-774a2b79a24f, Original Text (first 50 chars):  \n",
      "Name:  ___                   Unit No:   ___\n",
      " \n",
      "Ad..., Summary (first 50 chars): ## Discharge Summary for [Patient Name]\n",
      "\n",
      "**Admissi...\n",
      "Record ID: c5653c21-19b0-4bed-8ce1-cd5917ad7e3b, Original Text (first 50 chars):  \n",
      "Name:  ___                    Unit No:   ___\n",
      " \n",
      "A..., Summary (first 50 chars): ## Clinical Discharge Summary\n",
      "\n",
      "**Patient Informati...\n",
      "\n",
      "Verifying ChromaDB contents...\n",
      "Found 20 chunks in ChromaDB collection 'mimic_iv_summary_chunks_trial'.\n",
      "Chunk 1 (ID: deaca831-754e-442b-b5df-774a2b79a24f_0): ## Discharge Summary for [Patient Name]\n",
      "\n",
      "**Admission:** [Date]\n",
      "**Discharge:** [Date]\n",
      "**DOB:** [Date]...\n",
      "Chunk 2 (ID: deaca831-754e-442b-b5df-774a2b79a24f_1): **History of Present Illness:**\n",
      "- Patient presented with cramping abdominal pain, nausea, and biliou...\n",
      "\n",
      "Verifying CSV outputs...\n",
      "Found 8 CSV files in /kaggle/working/evaluation_results/\n",
      "\n",
      "CSV: /kaggle/working/evaluation_results/HBP-Exclusion_5_output_reverse_RAG_test.csv\n",
      "  Trial_Name    Criteria_Name                            Patient_id Eligibility         Evidence                                                                                                                                                                                                                                                                                                                                                                    MatchedChunk                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Patient_Summary  ROUGE-1  ROUGE-2  ROUGE-L  fuzz_MatchScore  CosineSimilarity\n",
      "0        HBP  HBP-Exclusion_5  deaca831-754e-442b-b5df-774a2b79a24f          No  Creatinine: 0.8  **Pertinent Results:**\\n- WBC: 12.5 (elevated), RBC: 4.46, HGB: 13.6, HCT: 39.7, PLT: 329\\n- Glucose: 151 (elevated), Urea N: 10, Creatinine: 0.8, Sodium: 142, Potassium: 3.8, Chloride: 105, Total CO2: 28, Anion Gap: 13\\n- CT of Abdomen/Pelvis: Indicated early small bowel obstruction with fecalization and interval worsening, likely physiologic fluid in the pelvis.  ## Discharge Summary for [Patient Name]\\n\\n**Admission:** [Date]\\n**Discharge:** [Date]\\n**DOB:** [Date]\\n**Sex:** Female\\n**Service:** Surgery\\n**Attending:** [Redacted]\\n\\n**Allergies:**\\n- Sulfonamides\\n- Codeine\\n- Bactrim\\n\\n**Chief Complaint:**\\n- Abdominal pain and vomiting\\n\\n**Major Surgical Procedure:**\\n- Exploratory laparotomy, lysis of adhesions, small bowel resection with enteroenterostomy.\\n\\n**History of Present Illness:**\\n- Patient presented with cramping abdominal pain, nausea, and bilious emesis. She experienced multiple episodes of vomiting and diarrhea, leading to an ED visit. No history of similar pain or small bowel obstruction.\\n\\n**Past Medical History:**\\n- Carcinoid tumor (status post right lung resection)\\n- Vitamin B12 deficiency\\n- Depression\\n- Hyperlipidemia\\n\\n**Past Surgical History:**\\n- Right lung resection\\n- Hysterectomy\\n- Right arm surgery\\n\\n**Physical Exam:**\\n- Vitals: Temp 96.9, HR 105, BP 108/92\\n- General: NAD, non-toxic but uncomfortable\\n- Cardiovascular: Tachycardia, no murmurs\\n- Respiratory: Decreased breath sounds on the right, clear lungs\\n- Abdomen: Soft, obese, minimally distended, diffuse tenderness, no guarding or rebound tenderness, low midline abdominal wound with no drainage or erythema\\n\\n**Pertinent Results:**\\n- WBC: 12.5 (elevated), RBC: 4.46, HGB: 13.6, HCT: 39.7, PLT: 329\\n- Glucose: 151 (elevated), Urea N: 10, Creatinine: 0.8, Sodium: 142, Potassium: 3.8, Chloride: 105, Total CO2: 28, Anion Gap: 13\\n- CT of Abdomen/Pelvis: Indicated early small bowel obstruction with fecalization and interval worsening, likely physiologic fluid in the pelvis.\\n\\n**Brief Hospital Course:**\\n- Admitted, made NPO, started IV fluids, and placed a nasogastric tube. Treated for fever (101°F). Nasogastric tube clamped on day 2, increased abdominal pain led to repeat CT showing increased obstruction. Surgery performed, tolerated well. Pain managed with morphine PCA. Nasogastric tube removed on post-op day 2, clear liquid diet started, advanced to a regular diet over 36 hours, and tolerated well. Bowel movements resumed, incision healing well, staples intact.\\n\\n**Discharge Medications:**\\n1. Albuterol: 2 puffs every 6 hours as needed\\n2. Fluticasone: 2 puffs twice a day\\n3. Oxycodone-Acetaminophen: [Dose] every 4 hours as needed\\n4. Docusate Sodium: 1 capsule twice a day\\n5. Simvastatin: 1 tablet daily\\n6. Trazodone: 1 tablet at bedtime\\n7. Wellbutrin: 1 tablet twice a day\\n\\n**Discharge Diagnosis:**\\n- High-grade small bowel obstruction\\n\\n**Discharge Condition:**\\n- Hemodynamically stable, tolerating a regular diet, having bowel movements, adequate pain control\\n\\n**Discharge Instructions:**\\n- Return to ED for new chest pain, worsening cough/wheezing, persistent vomiting, dehydration signs, blood in vomit/stool, burning/blood in urine, pain not improving within 24 hours, shaking chills, fever >101.5°F, or any new concerning symptoms.\\n- Resume regular home medications unless advised otherwise.\\n- Rest adequately, ambulate several times per day, drink fluids, avoid lifting >[Weight] lbs until follow-up with the surgeon.\\n- Avoid driving/heavy machinery while taking pain medications.\\n- Incision care: Call for increased pain/swelling/redness/drainage, avoid swimming/baths, shower with mild soap, remove remaining steri-strips [Days] after surgery.\\n\\n**Follow-up:**\\n- [Redacted]\\n\\n**Discharge Disposition:**\\n- Home     9.68     6.67     9.68            100.0             54.77\n",
      "1        HBP  HBP-Exclusion_5  c5653c21-19b0-4bed-8ce1-cd5917ad7e3b          No              NaN                                                                                                                                                                                                                                                                                                                                                                             NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ## Clinical Discharge Summary\\n\\n**Patient Information:**\\n- **Name:** Redacted\\n- **Date of Birth:** Redacted\\n- **Sex:** Male\\n- **Service:** Medicine\\n- **Admission Date:** Redacted\\n- **Discharge Date:** Redacted\\n- **Attending:** Redacted\\n- **Allergies:** No known allergies\\n\\n**Chief Complaint:**\\n- Visual hallucinations\\n\\n**History of Present Illness:**\\n- Male with [redacted disease], dyslipidemia, and history of prostate cancer (s/p prostatectomy) referred by his neurologist for worsening gait, falls, and visual hallucinations.\\n- Neurologist previously increased Mirapex but this caused hallucinations and confusion, leading to a decrease in dose. Despite this, gait stiffness and difficulty ambulating persisted.\\n- On admission day, experienced visual hallucinations and fell while transferring from couch to chair. Wife reported acute worsening of gait over the past 24 hours.\\n\\n**Physical Exam on Admission:**\\n- Vitals: Afebrile, normal heart rate, normotensive, SpO2 100% RA.\\n- Exam: Cogwheeling of upper extremities, decreased strength in lower extremities, normal sensation.\\n- Labs: Negative urine and serum tox screen, Na 132, K 5.8, negative troponin, normal LFTs, unremarkable CBC.\\n- Imaging: Chest X-ray showed mild atelectasis, CT head was unremarkable.\\n\\n**Hospital Course:**\\n- Evaluated by neurology, recommended admission to medicine for failure to thrive, continued home medications, and a toxo-metabolic workup.\\n- No acute distress, alert, but confused about reason for being in hospital. Denied recent falls, fever, chills, or other symptoms.\\n- Started on Quetiapine for hallucinations.\\n- Physical therapy recommended rehab, but family opted for home physical therapy.\\n\\n**Discharge Medications:**\\n1. Quetiapine Fumarate 25 mg PO QHS\\n2. Loratadine 10 mg PO DAILY\\n3. Pramipexole 0.625 mg PO TID\\n4. Pravastatin 40 mg PO QPM\\n5. Rasagiline 1 mg PO DAILY\\n6. Rivastigmine 9.5 mg/24 hr transdermal DAILY\\n\\n**Discharge Diagnosis:**\\n- [Redacted] Dementia\\n\\n**Discharge Condition:**\\n- Mental Status: Confused at times\\n- Level of Consciousness: Alert and interactive\\n\\n**Discharge Instructions:**\\n- Continue all medications and keep follow-up appointments.\\n\\n**Follow-Up:**\\n- Follow up on visual hallucination symptoms while on Seroquel.\\n- Continue home physical therapy.\\n\\n**Transitional Issues:**\\n- Follow up on visual hallucination symptoms on Seroquel.\\n- Follow up with home physical therapy.\\n\\n**Hospital Course Summary:**\\n- Admitted for worsening gait, falls, and visual hallucinations. Started on Quetiapine for hallucinations and continued home medications. Family opted for home physical therapy instead of rehab. Discharged in stable condition with instructions to continue medications and follow up for ongoing symptoms. \\n      NaN      NaN      NaN              NaN               NaN\n",
      "\n",
      "CSV: /kaggle/working/evaluation_results/HBP-Exclusion_4_output_reverse_RAG_test.csv\n",
      "  Trial_Name    Criteria_Name                            Patient_id Eligibility                                            Evidence                                                                                                                                                                                                                                                                                                                                                                                                   MatchedChunk                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Patient_Summary  ROUGE-1  ROUGE-2  ROUGE-L  fuzz_MatchScore  CosineSimilarity\n",
      "0        HBP  HBP-Exclusion_4  deaca831-754e-442b-b5df-774a2b79a24f          No  Carcinoid tumor (status post right lung resection)                                                                                                                                                                                                                                                                                                                        **Past Surgical History:**\\n- Right lung resection\\n- Hysterectomy\\n- Right arm surgery  ## Discharge Summary for [Patient Name]\\n\\n**Admission:** [Date]\\n**Discharge:** [Date]\\n**DOB:** [Date]\\n**Sex:** Female\\n**Service:** Surgery\\n**Attending:** [Redacted]\\n\\n**Allergies:**\\n- Sulfonamides\\n- Codeine\\n- Bactrim\\n\\n**Chief Complaint:**\\n- Abdominal pain and vomiting\\n\\n**Major Surgical Procedure:**\\n- Exploratory laparotomy, lysis of adhesions, small bowel resection with enteroenterostomy.\\n\\n**History of Present Illness:**\\n- Patient presented with cramping abdominal pain, nausea, and bilious emesis. She experienced multiple episodes of vomiting and diarrhea, leading to an ED visit. No history of similar pain or small bowel obstruction.\\n\\n**Past Medical History:**\\n- Carcinoid tumor (status post right lung resection)\\n- Vitamin B12 deficiency\\n- Depression\\n- Hyperlipidemia\\n\\n**Past Surgical History:**\\n- Right lung resection\\n- Hysterectomy\\n- Right arm surgery\\n\\n**Physical Exam:**\\n- Vitals: Temp 96.9, HR 105, BP 108/92\\n- General: NAD, non-toxic but uncomfortable\\n- Cardiovascular: Tachycardia, no murmurs\\n- Respiratory: Decreased breath sounds on the right, clear lungs\\n- Abdomen: Soft, obese, minimally distended, diffuse tenderness, no guarding or rebound tenderness, low midline abdominal wound with no drainage or erythema\\n\\n**Pertinent Results:**\\n- WBC: 12.5 (elevated), RBC: 4.46, HGB: 13.6, HCT: 39.7, PLT: 329\\n- Glucose: 151 (elevated), Urea N: 10, Creatinine: 0.8, Sodium: 142, Potassium: 3.8, Chloride: 105, Total CO2: 28, Anion Gap: 13\\n- CT of Abdomen/Pelvis: Indicated early small bowel obstruction with fecalization and interval worsening, likely physiologic fluid in the pelvis.\\n\\n**Brief Hospital Course:**\\n- Admitted, made NPO, started IV fluids, and placed a nasogastric tube. Treated for fever (101°F). Nasogastric tube clamped on day 2, increased abdominal pain led to repeat CT showing increased obstruction. Surgery performed, tolerated well. Pain managed with morphine PCA. Nasogastric tube removed on post-op day 2, clear liquid diet started, advanced to a regular diet over 36 hours, and tolerated well. Bowel movements resumed, incision healing well, staples intact.\\n\\n**Discharge Medications:**\\n1. Albuterol: 2 puffs every 6 hours as needed\\n2. Fluticasone: 2 puffs twice a day\\n3. Oxycodone-Acetaminophen: [Dose] every 4 hours as needed\\n4. Docusate Sodium: 1 capsule twice a day\\n5. Simvastatin: 1 tablet daily\\n6. Trazodone: 1 tablet at bedtime\\n7. Wellbutrin: 1 tablet twice a day\\n\\n**Discharge Diagnosis:**\\n- High-grade small bowel obstruction\\n\\n**Discharge Condition:**\\n- Hemodynamically stable, tolerating a regular diet, having bowel movements, adequate pain control\\n\\n**Discharge Instructions:**\\n- Return to ED for new chest pain, worsening cough/wheezing, persistent vomiting, dehydration signs, blood in vomit/stool, burning/blood in urine, pain not improving within 24 hours, shaking chills, fever >101.5°F, or any new concerning symptoms.\\n- Resume regular home medications unless advised otherwise.\\n- Rest adequately, ambulate several times per day, drink fluids, avoid lifting >[Weight] lbs until follow-up with the surgeon.\\n- Avoid driving/heavy machinery while taking pain medications.\\n- Incision care: Call for increased pain/swelling/redness/drainage, avoid swimming/baths, shower with mild soap, remove remaining steri-strips [Days] after surgery.\\n\\n**Follow-up:**\\n- [Redacted]\\n\\n**Discharge Disposition:**\\n- Home    35.29    26.67    35.29            56.57             59.45\n",
      "1        HBP  HBP-Exclusion_4  c5653c21-19b0-4bed-8ce1-cd5917ad7e3b          No      history of prostate cancer (s/p prostatectomy)  **History of Present Illness:**\\n- Male with [redacted disease], dyslipidemia, and history of prostate cancer (s/p prostatectomy) referred by his neurologist for worsening gait, falls, and visual hallucinations.\\n- Neurologist previously increased Mirapex but this caused hallucinations and confusion, leading to a decrease in dose. Despite this, gait stiffness and difficulty ambulating persisted                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ## Clinical Discharge Summary\\n\\n**Patient Information:**\\n- **Name:** Redacted\\n- **Date of Birth:** Redacted\\n- **Sex:** Male\\n- **Service:** Medicine\\n- **Admission Date:** Redacted\\n- **Discharge Date:** Redacted\\n- **Attending:** Redacted\\n- **Allergies:** No known allergies\\n\\n**Chief Complaint:**\\n- Visual hallucinations\\n\\n**History of Present Illness:**\\n- Male with [redacted disease], dyslipidemia, and history of prostate cancer (s/p prostatectomy) referred by his neurologist for worsening gait, falls, and visual hallucinations.\\n- Neurologist previously increased Mirapex but this caused hallucinations and confusion, leading to a decrease in dose. Despite this, gait stiffness and difficulty ambulating persisted.\\n- On admission day, experienced visual hallucinations and fell while transferring from couch to chair. Wife reported acute worsening of gait over the past 24 hours.\\n\\n**Physical Exam on Admission:**\\n- Vitals: Afebrile, normal heart rate, normotensive, SpO2 100% RA.\\n- Exam: Cogwheeling of upper extremities, decreased strength in lower extremities, normal sensation.\\n- Labs: Negative urine and serum tox screen, Na 132, K 5.8, negative troponin, normal LFTs, unremarkable CBC.\\n- Imaging: Chest X-ray showed mild atelectasis, CT head was unremarkable.\\n\\n**Hospital Course:**\\n- Evaluated by neurology, recommended admission to medicine for failure to thrive, continued home medications, and a toxo-metabolic workup.\\n- No acute distress, alert, but confused about reason for being in hospital. Denied recent falls, fever, chills, or other symptoms.\\n- Started on Quetiapine for hallucinations.\\n- Physical therapy recommended rehab, but family opted for home physical therapy.\\n\\n**Discharge Medications:**\\n1. Quetiapine Fumarate 25 mg PO QHS\\n2. Loratadine 10 mg PO DAILY\\n3. Pramipexole 0.625 mg PO TID\\n4. Pravastatin 40 mg PO QPM\\n5. Rasagiline 1 mg PO DAILY\\n6. Rivastigmine 9.5 mg/24 hr transdermal DAILY\\n\\n**Discharge Diagnosis:**\\n- [Redacted] Dementia\\n\\n**Discharge Condition:**\\n- Mental Status: Confused at times\\n- Level of Consciousness: Alert and interactive\\n\\n**Discharge Instructions:**\\n- Continue all medications and keep follow-up appointments.\\n\\n**Follow-Up:**\\n- Follow up on visual hallucination symptoms while on Seroquel.\\n- Continue home physical therapy.\\n\\n**Transitional Issues:**\\n- Follow up on visual hallucination symptoms on Seroquel.\\n- Follow up with home physical therapy.\\n\\n**Hospital Course Summary:**\\n- Admitted for worsening gait, falls, and visual hallucinations. Started on Quetiapine for hallucinations and continued home medications. Family opted for home physical therapy instead of rehab. Discharged in stable condition with instructions to continue medications and follow up for ongoing symptoms. \\n    23.73    21.05    23.73           100.00             61.86\n",
      "* Running on local URL:  http://0.0.0.0:7860\n",
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "* Running on public URL: https://758c08d2a75b9d2d09.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://758c08d2a75b9d2d09.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:00<00:00, 103MiB/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt, retry_if_exception_type\n",
    "from google.api_core.exceptions import ResourceExhausted, InternalServerError, ServiceUnavailable, DeadlineExceeded\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "import sqlite3\n",
    "import uuid\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from chromadb.errors import InvalidCollectionException\n",
    "from rouge_score import rouge_scorer\n",
    "from rapidfuzz import fuzz\n",
    "import gradio as gr\n",
    "import shutil\n",
    "import io\n",
    "import sys\n",
    "import logging\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tqdm.pandas()\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "log_buffer = io.StringIO()\n",
    "stream_handler = logging.StreamHandler(log_buffer)\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(stream_handler)\n",
    "log_file_handler = logging.FileHandler(\"/kaggle/working/pipeline.log\")\n",
    "log_file_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(log_file_handler)\n",
    "\n",
    "# Configuration: API Key Setup\n",
    "try:\n",
    "    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"Google_API_Key\")\n",
    "except ImportError:\n",
    "    GOOGLE_API_KEY = \"YOUR_API_KEY_HERE\"  # Replace with your API key\n",
    "try:\n",
    "    client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "    client.models.list()\n",
    "    print(\"✅ API client initialized successfully.\")\n",
    "    logger.info(\"✅ API client initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to initialize Google API client: {e}\")\n",
    "    logger.error(f\"Failed to initialize Google API client: {e}\")\n",
    "    raise\n",
    "\n",
    "# Initialize ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# LangGraph State\n",
    "class PipelineState(TypedDict):\n",
    "    raw_text: List[str]\n",
    "    summaries: List[str]\n",
    "    summary_ids: List[str]\n",
    "    criteria_prompts: List[dict]\n",
    "    chunk_ids: List[str]\n",
    "    eligibility_results: List[dict]\n",
    "    embedding_function: EmbeddingFunction\n",
    "    evaluation_results: List[dict]\n",
    "    trial_names: List[str]\n",
    "\n",
    "# Summarization Function\n",
    "def summarize_text(state: PipelineState) -> PipelineState:\n",
    "    print(\"Starting summarization step...\")\n",
    "    logger.info(\"Starting summarization step...\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    print(\"Loading dataset...\")\n",
    "    logger.info(\"Loading dataset...\")\n",
    "    try:\n",
    "        df = pd.read_csv('/kaggle/input/mimic-iv-2/mimic_iv_summarization_test_dataset_shortened_edited.csv')\n",
    "        df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "        print(f\"Dataset loaded: {len(df_train)} training, {len(df_test)} test samples.\")\n",
    "        logger.info(f\"Dataset loaded: {len(df_train)} training, {len(df_test)} test samples.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        logger.error(f\"Error loading dataset: {e}\")\n",
    "        raise\n",
    "    \n",
    "    for i, text in enumerate(state['raw_text']):\n",
    "        print(f\"Input {i+1} (length: {len(text)}): {text[:100]}...\")\n",
    "        logger.info(f\"Input {i+1} (length: {len(text)}): {text[:100]}...\")\n",
    "        if not text.strip() or text.count(\"___\") > 10:\n",
    "            print(f\"Warning: Input {i+1} may contain excessive placeholders or be empty.\")\n",
    "            logger.warning(f\"Input {i+1} may contain excessive placeholders or be empty.\")\n",
    "    \n",
    "    input_data = {\n",
    "        'examples': \n",
    "            df_train[['text', 'summary']]\n",
    "            .rename(columns={'text': 'textInput', 'summary': 'output'})\n",
    "            .to_dict(orient='records')\n",
    "    }\n",
    "\n",
    "    print(f\"input data length: {len(input_data)}\")\n",
    "    print(\"Prepared input data for fine-tuning.\")\n",
    "    logger.info(\"Prepared input data for fine-tuning.\")\n",
    "    \n",
    "    model_id = None\n",
    "    queued_model = None\n",
    "    try:\n",
    "        for m in reversed(client.tunings.list()):\n",
    "            if m.name.startswith('tunedModels/summarization-model'):\n",
    "                if m.state.name == 'JOB_STATE_SUCCEEDED':\n",
    "                    # model_id = m.name\n",
    "                    # print(f'Found existing tuned model to reuse: {model_id}')\n",
    "                    # logger.info(f'Found existing tuned model to reuse: {model_id}')\n",
    "                    model_id = 'tunedModels/summarization-model-9zeddx1lwavq'\n",
    "                    break\n",
    "                elif m.state.name == 'JOB_STATE_RUNNING' and not queued_model:\n",
    "                    queued_model = m.name\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking existing tuned models: {e}\")\n",
    "        logger.error(f\"Error checking existing tuned models: {e}\")\n",
    "    \n",
    "    if queued_model and not model_id:\n",
    "        model_id = queued_model\n",
    "        print(f'Found queued model, still waiting: {model_id}')\n",
    "        logger.info(f'Found queued model, still waiting: {model_id}')\n",
    "        try:\n",
    "            while not (tuned_model := client.tunings.get(name=model_id)).has_ended:\n",
    "                print(f'Tuning state: {tuned_model.state}')\n",
    "                logger.info(f'Tuning state: {tuned_model.state}')\n",
    "                time.sleep(60)\n",
    "            if not tuned_model.has_succeeded and tuned_model.error:\n",
    "                print(f\"Error during tuning: {tuned_model.error}\")\n",
    "                logger.error(f\"Error during tuning: {tuned_model.error}\")\n",
    "                model_id = None\n",
    "        except Exception as e:\n",
    "            print(f\"Error waiting for queued model: {e}\")\n",
    "            logger.error(f\"Error waiting for queued model: {e}\")\n",
    "            model_id = None\n",
    "    \n",
    "    if not model_id:\n",
    "        try:\n",
    "            print(\"Starting fine-tuning...\")\n",
    "            logger.info(\"Starting fine-tuning...\")\n",
    "            tuning_op = client.tunings.tune(\n",
    "                base_model=\"models/gemini-1.5-flash-001-tuning\",\n",
    "                training_dataset=input_data,\n",
    "                config=types.CreateTuningJobConfig(\n",
    "                    tuned_model_display_name=\"Summarization model\",\n",
    "                    batch_size=16,\n",
    "                    epoch_count=2,\n",
    "                ),\n",
    "            )\n",
    "            model_id = tuning_op.name\n",
    "            print(f'Started tuning job: {model_id}')\n",
    "            logger.info(f'Started tuning job: {model_id}')\n",
    "            while not (tuned_model := client.tunings.get(name=model_id)).has_ended:\n",
    "                print(f'Tuning state: {tuned_model.state}')\n",
    "                logger.info(f'Tuning state: {tuned_model.state}')\n",
    "                time.sleep(60)\n",
    "            if not tuned_model.has_succeeded and tuned_model.error:\n",
    "                print(f\"Error during tuning: {tuned_model.error}\")\n",
    "                logger.error(f\"Error during tuning: {tuned_model.error}\")\n",
    "                raise Exception(f\"Tuning failed: {tuned_model.error}\")\n",
    "            print(\"✅ Fine-tuning completed successfully.\")\n",
    "            logger.info(\"✅ Fine-tuning completed successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fine-tune model: {e}\")\n",
    "            logger.error(f\"Failed to fine-tune model: {e}\")\n",
    "            model_id = \"gemini-1.5-flash-001\"\n",
    "            print(f\"Using pre-trained model: {model_id}\")\n",
    "            logger.info(f\"Using pre-trained model: {model_id}\")\n",
    "    \n",
    "    @retry(\n",
    "        wait=wait_random_exponential(min=1, max=20),\n",
    "        stop=stop_after_attempt(15),\n",
    "        retry=retry_if_exception_type((ResourceExhausted, InternalServerError, ServiceUnavailable, DeadlineExceeded))\n",
    "    )\n",
    "    def generate_summary(text: str) -> str:\n",
    "        print(f\"Generating summary for text (length: {len(text)})...\")\n",
    "        logger.info(f\"Generating summary for text (length: {len(text)})...\")\n",
    "        prompt = f\"\"\"\n",
    "        Summarize the following clinical discharge note in a concise and detailed manner. Include key information such as primary diagnoses, major treatments, procedures, and outcomes. Exclude placeholders (e.g., '___') and focus on clinical content. The summary should be no longer than 500 words and written in a professional medical tone.\n",
    "\n",
    "        Clinical Note:\n",
    "        {text}\n",
    "        \"\"\"\n",
    "\n",
    "        print(f'model_id: {model_id}')\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=model_id,\n",
    "                contents=prompt,\n",
    "                config=types.GenerateContentConfig()\n",
    "            )\n",
    "            rc = response.candidates[0]\n",
    "            print(f\"API Finish Reason: {rc.finish_reason.name}\")\n",
    "            logger.info(f\"API Finish Reason: {rc.finish_reason.name}\")\n",
    "            if rc.finish_reason.name != \"STOP\":\n",
    "                print(f\"Warning: Incomplete response (reason: {rc.finish_reason.name})\")\n",
    "                logger.warning(f\"Incomplete response (reason: {rc.finish_reason.name})\")\n",
    "            summary = rc.content.parts[0].text\n",
    "            if not summary.strip() or len(summary) < 50:\n",
    "                print(f\"Warning: Summary is empty or too short (length: {len(summary)})\")\n",
    "                logger.warning(f\"Summary is empty or too short (length: {len(summary)})\")\n",
    "                return \"(error: empty or invalid summary)\"\n",
    "            print(f\"Summary generated (length: {len(summary)}): {summary[:100]}...\")\n",
    "            logger.info(f\"Summary generated (length: {len(summary)}): {summary[:100]}...\")\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating summary: {e}\")\n",
    "            logger.error(f\"Error generating summary: {e}\")\n",
    "            return f\"(error: {str(e)})\"\n",
    "    \n",
    "    state['summaries'] = []\n",
    "    for text in state['raw_text']:\n",
    "        summary = generate_summary(text)\n",
    "        if \"(error\" in summary.lower():\n",
    "            print(f\"Skipping invalid summary: {summary[:100]}...\")\n",
    "            logger.warning(f\"Skipping invalid summary: {summary[:100]}...\")\n",
    "        else:\n",
    "            state['summaries'].append(summary)\n",
    "    \n",
    "    print(f\"✅ Generated {len(state['summaries'])} valid summaries.\")\n",
    "    logger.info(f\"✅ Generated {len(state['summaries'])} valid summaries.\")\n",
    "    print(\"Sample summaries:\", [s[:100] for s in state['summaries'][:2]])\n",
    "    logger.info(\"Sample summaries: %s\", [s[:100] for s in state['summaries'][:2]])\n",
    "    if not state['summaries']:\n",
    "        print(\"❌ No valid summaries generated. Pipeline will continue with empty summaries.\")\n",
    "        logger.error(\"❌ No valid summaries generated. Pipeline will continue with empty summaries.\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Database Storage Function\n",
    "def store_in_database(state: PipelineState) -> PipelineState:\n",
    "    print(\"Starting database storage step...\")\n",
    "    logger.info(\"Starting database storage step...\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    db_path = \"/kaggle/working/clinical_data.db\"\n",
    "    \n",
    "    try:\n",
    "        with sqlite3.connect(db_path) as conn:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS summaries (\n",
    "                    id TEXT PRIMARY KEY,\n",
    "                    original_text TEXT,\n",
    "                    summary TEXT,\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                )\n",
    "            \"\"\")\n",
    "            conn.commit()\n",
    "        print(f\"✅ Database initialized at {db_path}.\")\n",
    "        logger.info(f\"✅ Database initialized at {db_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing database: {e}\")\n",
    "        logger.error(f\"Error initializing database: {e}\")\n",
    "        raise\n",
    "    \n",
    "    summary_ids = []\n",
    "    for text, summary in zip(state['raw_text'], state['summaries'] + [\"\"] * (len(state['raw_text']) - len(state['summaries']))):\n",
    "        if \"(error\" in summary.lower() or not summary.strip():\n",
    "            print(f\"Skipping storage for invalid summary: {summary[:100]}...\")\n",
    "            logger.warning(f\"Skipping storage for invalid summary: {summary[:100]}...\")\n",
    "            continue\n",
    "        record_id = str(uuid.uuid4())\n",
    "        try:\n",
    "            with sqlite3.connect(db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "                cursor.execute(\n",
    "                    \"INSERT INTO summaries (id, original_text, summary) VALUES (?, ?, ?)\",\n",
    "                    (record_id, text, summary)\n",
    "                )\n",
    "                conn.commit()\n",
    "            print(f\"Stored summary (ID: {record_id}, summary length: {len(summary)}).\")\n",
    "            logger.info(f\"Stored summary (ID: {record_id}, summary length: {len(summary)}).\")\n",
    "            summary_ids.append(record_id)\n",
    "        except Exception as e:\n",
    "            print(f\"Error storing summary (ID: {record_id}): {e}\")\n",
    "            logger.error(f\"Error storing summary (ID: {record_id}): {e}\")\n",
    "            raise\n",
    "    \n",
    "    state['summary_ids'] = summary_ids\n",
    "    print(f\"✅ Stored {len(summary_ids)} summaries in database.\")\n",
    "    logger.info(f\"✅ Stored {len(summary_ids)} summaries in database.\")\n",
    "    return state\n",
    "\n",
    "# Criteria Processing Function\n",
    "def process_criteria(state: PipelineState) -> PipelineState:\n",
    "    print(\"Starting criteria processing step...\")\n",
    "    logger.info(\"Starting criteria processing step...\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    csv_folder = \"/kaggle/input/clinical-trial-sample\"\n",
    "    output_dir = \"/kaggle/working/Criteria_based_Prompts\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    csv_files = glob.glob(os.path.join(csv_folder, \"*.csv\"))\n",
    "    print(f\"Found {len(csv_files)} CSV files in {csv_folder}.\")\n",
    "    logger.info(f\"Found {len(csv_files)} CSV files in {csv_folder}.\")\n",
    "    \n",
    "    criteria_prompts = []\n",
    "    trial_names = []\n",
    "    \n",
    "    for file_path in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            if 'Criteria_name' not in df.columns or 'Content' not in df.columns:\n",
    "                print(f\"❌ Skipping {file_path}: Missing 'Criteria_name' or 'Content' columns.\")\n",
    "                logger.error(f\"❌ Skipping {file_path}: Missing 'Criteria_name' or 'Content' columns.\")\n",
    "                continue\n",
    "            df = df[['Criteria_name', 'Content']]\n",
    "            base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "            trial_names.append(base_name)\n",
    "            json_filename = os.path.join(\"/kaggle/working\", f\"{base_name}.json\")\n",
    "            \n",
    "            df.to_json(json_filename, orient='records', lines=False)\n",
    "            print(f\"Converted {file_path} to {json_filename}.\")\n",
    "            logger.info(f\"Converted {file_path} to {json_filename}.\")\n",
    "            \n",
    "            with open(json_filename, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            cot_prompt = '''{\n",
    "  \"instructions\": \"You are a medical data analyst specialized in creating prompts for LLMs to process clinical trial criteria. Given a document containing two sections, 'Criteria' and 'Content', review the document and create an LLM prompt for each criterion by following the steps below.\",\n",
    "  \"global_instructions\": {\n",
    "    \"processing_steps\": [\n",
    "      \"1. Think through each step wisely.\",\n",
    "      \"2. Go through each criterion one-by-one.\",\n",
    "      \"3. Return the criterion name as 'Criteria_name'.\",\n",
    "      \"4. Return the context of the criterion specified in the associated 'Content' as 'Text' and add clarification/interpretation.\",\n",
    "      \"5. The 'Text' should not be more than 2 sentences.\",\n",
    "      \"6. Specify less than 10 steps for chain of thoughts (step-by-step reasoning) for an LLM to help process each criterion.\",\n",
    "      \"7. The created prompt must emphasize on the fact that the model **is not allowed to infer** a condition based on the **symptoms or medication**, and all the evidences extracted **must have an actual match** in the **clinical note**.\",\n",
    "      \"8. The created prompt must emphasize on the fact that the model must only extract the conditions pertinent to the patients only (not their family).\",\n",
    "      \"9. If the criterion is condition or medication related, bring some examples for more clarity as 'extractableLexicons'. Return an empty list '[]' if the criteria is not condition or medication related.\",\n",
    "      \"10. Ensure the number of arrays match the total number of criteria.\",\n",
    "      \"11. Use the global output format for all criteria evaluation results.\"\n",
    "    ],\n",
    "    \"output_format\": {\n",
    "      \"format_instructions\": [\n",
    "        \"1. You must always return **a valid JSON array**.\",\n",
    "        \"2. You must return the **eligibility** of the patient as 'Yes' or 'No'.\",\n",
    "        \"3. You must return the **evidences** of the criterion met if available. If the patient doesn't have any evidences to be eligible, return None.\",\n",
    "        \"4. You should return an array for each matched evidence.\",\n",
    "        \"5. Your output must look like the following: {\\\"summary_id\\\": \\\"ID\\\", \\\"Eligibility\\\": \\\"Yes\\\" or \\\"No\\\", \\\"Evidence\\\": \\\"The relevant evidence or None\\\"}\"\n",
    "      ]\n",
    "    },\n",
    "    \"final_output_structure\": [\n",
    "      {\n",
    "        \"Criteria_name\": \"name of the criteria\",\n",
    "        \"Text\": \"the context of the criterion and interpretation/clarification\",\n",
    "        \"chainOfThought\": [\n",
    "          \"Step 1: the relevant step\",\n",
    "          \"Step 2: the relevant step\",\n",
    "          \"Step 3: the relevant step\",\n",
    "          \"...\"\n",
    "        ],\n",
    "        \"extractableLexicons\": \"2-4 examples, if the criterion is medication or condition related\",\n",
    "        \"Output\": [\n",
    "          \"1. You must always return **a valid JSON array**.\",\n",
    "          \"2. You must return the **eligibility** of the patient as 'Yes' or 'No'.\",\n",
    "          \"3. You must return the **evidences** of the criterion met if available. If the patient doesn't have any evidences to be eligible, return None.\",\n",
    "          \"4. You should return an array for each matched evidence.\",\n",
    "          \"5. Your output must look like the following: {\\\"summary_id\\\": \\\"ID\\\", \\\"Eligibility\\\": \\\"Yes\\\" or \\\"No\\\", \\\"Evidence\\\": \\\"The relevant evidence or None\\\"}\"\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"Example_Input\": [\n",
    "    {\n",
    "      \"Criteria_name\": \"Inclusion_1\", \n",
    "      \"Content\": \"CKD (eGFR of less than 60 mL/min/1.73 m²)\"\n",
    "    },\n",
    "    {\n",
    "      \"Criteria_name\": \"Exclusion_1\", \n",
    "      \"Content\": \"Known HF hospitalization history\"\n",
    "    }\n",
    "  ],\n",
    "  \"Example_Output\": [\n",
    "    {\n",
    "      \"Criteria_name\": \"Inclusion_1\",\n",
    "      \"Text\": \"Clinical diagnosis of CKD or an estimated glomerular filtration rate (eGFR) of less than 60 mL/min/1.73 m².\",\n",
    "      \"chainOfThought\": [\n",
    "        \"Step 1: Check if the patient has a documented clinical diagnosis of CKD in their medical records.\",\n",
    "        \"Step 2: If any related lexicon is specified in 'extractableLexicons', use as example. But you should search for other synonyms as well.\",\n",
    "        \"Step 3: You are **not allowed to infer** a condition based on the **symptoms or medication**.\",\n",
    "        \"Step 4: You must only extract the conditions **pertinent to the patients** only (not their family).\",\n",
    "        \"Step 5: Only extract the evidences that have an actual match in the text.\",\n",
    "        \"Step 6: Verify if the patient has any eGFR value recorded.\",\n",
    "        \"Step 7: Check if the patient's eGFR is less than 60 mL/min/1.73 m².\",\n",
    "        \"Step 8: If any of the conditions in steps 1 or 6 are met, set 'eligibility' as 'Yes', set 'No' otherwise.\",\n",
    "        \"Step 9: Return the eligibility evidences as 'Evidence'.\"\n",
    "      ],\n",
    "      \"extractableLexicons\": [\n",
    "        \"estimated glomerular filtration rate < 60 mL/min/1.73 m²\",\n",
    "        \"eGFR < 60 mL/min/1.73 m²\",\n",
    "        \"eGFR = 55 mL/min/1.73 m²\",\n",
    "        \"chronic kidney disease\",\n",
    "        \"CKD\"\n",
    "      ],\n",
    "      \"Output\": [\n",
    "        \"1. You must always return **a valid JSON array**.\",\n",
    "        \"2. You must return the **eligibility** of the patient as 'Yes' or 'No'.\",\n",
    "        \"3. You must return the **evidences** of the criterion met if available. If the patient doesn't have any evidences to be eligible, return None.\",\n",
    "        \"4. You should return an array for each matched evidence.\",\n",
    "        \"5. Your output must look like the following: {\\\"summary_id\\\": \\\"ID\\\", \\\"Eligibility\\\": \\\"Yes\\\" or \\\"No\\\", \\\"Evidence\\\": \\\"The relevant evidence or None\\\"}\"\n",
    "      ]\n",
    "    },\n",
    "    { \n",
    "      \"Criteria_name\": \"Exclusion_1\",\n",
    "      \"Text\": \"History of known Heart Failure hospitalization\",\n",
    "      \"chainOfThought\": [\n",
    "        \"Step 1: Check the patient's hospitalization history for any admissions related to heart failure.\",\n",
    "        \"Step 2: If any related lexicon is specified in 'extractableLexicons', use as example. But you should search for other synonyms as well.\",\n",
    "        \"Step 3: Look for discharge diagnoses that include heart failure or related terms.\",\n",
    "        \"Step 4: You are **not allowed to infer** a condition based on the **symptoms or medications**.\",\n",
    "        \"Step 5: You must only extract the conditions **pertinent to the patients** only (not their family).\",\n",
    "        \"Step 6: Only extract the evidences that have an actual match in text.\",\n",
    "        \"Step 7: If any hospitalization for HF is documented, this exclusion criterion is met and you should return 'Yes' as 'eligibility'. Return 'No', otherwise.\",\n",
    "        \"Step 8: If any hospitalization for HF is documented return the evidence as 'Evidence'. Return None, otherwise.\"\n",
    "      ],\n",
    "      \"extractableLexicons\": [\n",
    "        \"heart failure hospitalization\",\n",
    "        \"admitted for CHF\",\n",
    "        \"hospitalized due to heart failure\",\n",
    "        \"inpatient stay for cardiac failure\"\n",
    "      ],\n",
    "      \"Output\": [\n",
    "        \"1. You must always return **a valid JSON array**.\",\n",
    "        \"2. You must return the **eligibility** of the patient as 'Yes' or 'No'.\",\n",
    "        \"3. You must return the **evidences** of the criterion met if available. If the patient doesn't have any evidences to be eligible, return None.\",\n",
    "        \"4. You should return an array for each matched evidence.\",\n",
    "        \"5. Your output must look like the following: {\\\"summary_id\\\": \\\"ID\\\", \\\"Eligibility\\\": \\\"Yes\\\" or \\\"No\\\", \\\"Evidence\\\": \\\"The relevant evidence or None\\\"}\"\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"response_format_instructions\": \"When generating LLM prompts for clinical trial criteria, use the following structure for each criterion. Each prompt should follow the global instructions while providing specific guidance for evaluating that particular criterion. Output should consistently reference the global output format and avoid redundancy.\",\n",
    "  \"expected_model_response\": {\n",
    "    \"format\": {\n",
    "      \"summary_id\": \"Patient summary ID\",\n",
    "      \"Eligibility\": \"Yes or No\",\n",
    "      \"Evidence\": \"Relevant text from clinical note or None\"\n",
    "    }\n",
    "  }\n",
    "}'''\n",
    "            \n",
    "            prompt = cot_prompt + f\"\\nYou are given a JSON-formatted clinical trial criteria description below. PASSAGE:\\n{json.dumps(data)}\\n\"\n",
    "            \n",
    "            try:\n",
    "                response = client.models.generate_content(\n",
    "                    model=\"gemini-1.5-flash\",\n",
    "                    contents=prompt,\n",
    "                    config=types.GenerateContentConfig()\n",
    "                )\n",
    "                response_text = response.candidates[0].content.parts[0].text\n",
    "                response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                parsed = json.loads(response_text)\n",
    "                \n",
    "                subfolder = os.path.join(output_dir, base_name)\n",
    "                os.makedirs(subfolder, exist_ok=True)\n",
    "                \n",
    "                for item in parsed:\n",
    "                    item['Trial_Name'] = base_name\n",
    "                    filename = f\"{item['Criteria_name']}.json\"\n",
    "                    filepath = os.path.join(subfolder, filename)\n",
    "                    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "                        json.dump(item, f, ensure_ascii=False, indent=2)\n",
    "                    criteria_prompts.append(item)\n",
    "                \n",
    "                print(f\"✅ Processed {base_name}: {len(parsed)} prompts written to {subfolder}.\")\n",
    "                logger.info(f\"✅ Processed {base_name}: {len(parsed)} prompts written to {subfolder}.\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error generating prompts for {json_filename}: {e}\")\n",
    "                logger.error(f\"❌ Error generating prompts for {json_filename}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {file_path}: {e}\")\n",
    "            logger.error(f\"❌ Error processing {file_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    state['criteria_prompts'] = criteria_prompts\n",
    "    state['trial_names'] = list(set(trial_names))\n",
    "    print(f\"✅ Generated {len(criteria_prompts)} criteria prompts.\")\n",
    "    logger.info(f\"✅ Generated {len(criteria_prompts)} criteria prompts.\")\n",
    "    print(f\"✅ Found {len(state['trial_names'])} trial names: {state['trial_names']}\")\n",
    "    logger.info(f\"✅ Found {len(state['trial_names'])} trial names: {state['trial_names']}\")\n",
    "    return state\n",
    "\n",
    "# Chunking and Embedding Function\n",
    "def chunk_and_embed(state: PipelineState) -> PipelineState:\n",
    "    print(\"Starting chunking and embedding step...\")\n",
    "    logger.info(\"Starting chunking and embedding step...\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # Initialize ChromaDB client\n",
    "    chromadb_path = CHROMA_DB_PATH\n",
    "    # import os\n",
    "    # import shutil\n",
    "    \n",
    "    # if os.path.exists(chromadb_path):\n",
    "    #     try:\n",
    "    #         shutil.rmtree(chromadb_path)\n",
    "    #         print(f\"✅ Successfully removed directory: {chromadb_path}\")\n",
    "    #     except OSError as e:\n",
    "    #         print(f\"❌ Error removing directory {chromadb_path}: {e}\")\n",
    "    # else:\n",
    "    #     print(f\"⚠️ Directory does not exist: {chromadb_path}\")\n",
    "\n",
    "    \n",
    "    os.makedirs(chromadb_path, exist_ok=True)\n",
    "    try:\n",
    "        chroma_client = chromadb.PersistentClient(path=chromadb_path)\n",
    "        print(f\"✅ Persistent ChromaDB client initialized at {chromadb_path}.\")\n",
    "        logger.info(f\"✅ Persistent ChromaDB client initialized at {chromadb_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error initializing persistent ChromaDB client: {e}\")\n",
    "        logger.error(f\"❌ Error initializing persistent ChromaDB client: {e}\")\n",
    "        raise\n",
    "    \n",
    "    class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "        def __init__(self):\n",
    "            self.document_mode = True\n",
    "        \n",
    "        @retry(\n",
    "            wait=wait_random_exponential(min=1, max=10),\n",
    "            stop=stop_after_attempt(5),\n",
    "            retry=retry_if_exception_type((ResourceExhausted, InternalServerError, ServiceUnavailable, DeadlineExceeded))\n",
    "        )\n",
    "        def __call__(self, input: Documents) -> Embeddings:\n",
    "            task = \"retrieval_document\" if self.document_mode else \"retrieval_query\"\n",
    "            try:\n",
    "                response = client.models.embed_content(\n",
    "                    model=\"models/text-embedding-004\",\n",
    "                    contents=input,\n",
    "                    config=types.EmbedContentConfig(task_type=task),\n",
    "                )\n",
    "                embeddings = [e.values for e in response.embeddings]\n",
    "                print(f\"Generated {len(embeddings)} embeddings with dimension {len(embeddings[0])}\")\n",
    "                logger.info(f\"Generated {len(embeddings)} embeddings with dimension {len(embeddings[0])}\")\n",
    "                return embeddings\n",
    "            except Exception as e:\n",
    "                print(f\"Retrying due to error: {e}\")\n",
    "                logger.error(f\"Retrying due to error: {e}\")\n",
    "                raise\n",
    "    \n",
    "    embed_fn = GeminiEmbeddingFunction()\n",
    "    embed_fn.document_mode = True\n",
    "    state['embedding_function'] = embed_fn\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=450,\n",
    "        chunk_overlap=50,\n",
    "        separators=[\"\\n\\n\", \"\\n**\", \".\", \" \"]\n",
    "    )\n",
    "    \n",
    "    all_chunks = []\n",
    "    chunk_ids = []\n",
    "    for idx, summary in enumerate(state['summaries']):\n",
    "        if \"(error\" in summary.lower() or not summary.strip():\n",
    "            print(f\"⚠️ Skipping summary {idx+1} due to error or empty: {summary[:100]}...\")\n",
    "            logger.warning(f\"⚠️ Skipping summary {idx+1} due to error or empty: {summary[:100]}...\")\n",
    "            continue\n",
    "        chunks = splitter.split_text(summary)\n",
    "        if not chunks:\n",
    "            print(f\"⚠️ No chunks generated for summary {idx+1}\")\n",
    "            logger.warning(f\"⚠️ No chunks generated for summary {idx+1}\")\n",
    "            continue\n",
    "        all_chunks.extend(chunks)\n",
    "        chunk_ids.extend([f\"{state['summary_ids'][idx]}_{i}\" for i in range(len(chunks))])\n",
    "    \n",
    "    print(f\"Generated {len(all_chunks)} chunks from {len(state['summaries'])} summaries.\")\n",
    "    logger.info(f\"Generated {len(all_chunks)} chunks from {len(state['summaries'])} summaries.\")\n",
    "    print(f\"Sample chunks: {all_chunks[:2]}\")\n",
    "    logger.info(f\"Sample chunks: {all_chunks[:2]}\")\n",
    "    print(f\"Sample chunk IDs: {chunk_ids[:2]}\")\n",
    "    logger.info(f\"Sample chunk IDs: {chunk_ids[:2]}\")\n",
    "\n",
    "    \n",
    "    # Ensure collection exists\n",
    "    collection = None\n",
    "    try:\n",
    "        collection = chroma_client.get_collection(name=\"mimic_iv_summary_chunks_trial\")\n",
    "        print(\"✅ Collection 'mimic_iv_summary_chunks_trial' already exists.\")\n",
    "        logger.info(\"✅ Collection 'mimic_iv_summary_chunks_trial' already exists.\")\n",
    "    except (ValueError, InvalidCollectionException) as e:\n",
    "        print(f\"Collection does not exist: {e}. Creating new collection 'mimic_iv_summary_chunks_trial'...\")\n",
    "        logger.info(f\"Collection does not exist: {e}. Creating new collection 'mimic_iv_summary_chunks_trial'...\")\n",
    "        try:\n",
    "            collection = chroma_client.create_collection(\n",
    "                name=\"mimic_iv_summary_chunks_trial\",\n",
    "                embedding_function=embed_fn,\n",
    "                metadata={\"hnsw:space\": \"cosine\"}\n",
    "            )\n",
    "            print(\"✅ Collection created successfully.\")\n",
    "            logger.info(\"✅ Collection created successfully.\")\n",
    "        except Exception as create_e:\n",
    "            print(f\"❌ Failed to create collection: {create_e}\")\n",
    "            logger.error(f\"❌ Failed to create collection: {create_e}\")\n",
    "            raise\n",
    "    \n",
    "    # Store chunks if available\n",
    "    if all_chunks:\n",
    "        try:\n",
    "            collection.add(documents=all_chunks, ids=chunk_ids)\n",
    "            print(f\"✅ Stored {collection.count()} chunks in ChromaDB collection 'mimic_iv_summary_chunks_trial'.\")\n",
    "            logger.info(f\"✅ Stored {collection.count()} chunks in ChromaDB collection 'mimic_iv_summary_chunks_trial'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error adding chunks to ChromaDB: {e}\")\n",
    "            logger.error(f\"❌ Error adding chunks to ChromaDB: {e}\")\n",
    "            raise\n",
    "    else:\n",
    "        print(\"⚠️ No chunks to store. Collection created but empty.\")\n",
    "        logger.warning(\"⚠️ No chunks to store. Collection created but empty.\")\n",
    "    \n",
    "    # Verify collection exists\n",
    "    try:\n",
    "        collection = chroma_client.get_collection(name=\"mimic_iv_summary_chunks_trial\")\n",
    "        print(f\"✅ Verified collection exists with {collection.count()} chunks.\")\n",
    "        logger.info(f\"✅ Verified collection exists with {collection.count()} chunks.\")\n",
    "        \n",
    "    except (ValueError, InvalidCollectionException) as e:\n",
    "        print(f\"❌ Collection verification failed: {e}\")\n",
    "        logger.error(f\"❌ Collection verification failed: {e}\")\n",
    "        raise\n",
    "    \n",
    "    state['chunk_ids'] = chunk_ids\n",
    "    print(f\"✅ Stored {len(chunk_ids)} chunk IDs.\")\n",
    "    logger.info(f\"✅ Stored {len(chunk_ids)} chunk IDs.\")\n",
    "    return state\n",
    "\n",
    "# Eligibility Checking Function\n",
    "def evaluate_eligibility(state: PipelineState) -> PipelineState:\n",
    "    print(\"Starting eligibility checking step...\")\n",
    "    logger.info(\"Starting eligibility checking step...\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    try:\n",
    "        chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "        try:\n",
    "            collection = chroma_client.get_collection(\n",
    "                name=\"mimic_iv_summary_chunks_trial\",\n",
    "                embedding_function=state['embedding_function']\n",
    "            )\n",
    "            print(f\"✅ ChromaDB collection loaded with {collection.count()} chunks.\")\n",
    "            logger.info(f\"✅ ChromaDB collection loaded with {collection.count()} chunks.\")\n",
    "        except (ValueError, InvalidCollectionException) as e:\n",
    "            print(f\"❌ Collection 'mimic_iv_summary_chunks_trial' does not exist: {e}\")\n",
    "            logger.error(f\"❌ Collection 'mimic_iv_summary_chunks_trial' does not exist: {e}\")\n",
    "            raise\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error initializing persistent ChromaDB client: {e}\")\n",
    "        logger.error(f\"❌ Error initializing persistent ChromaDB client: {e}\")\n",
    "        raise\n",
    "    \n",
    "    eligibility_results = []\n",
    "    \n",
    "    # Skip if no chunks or summaries\n",
    "    if not state['chunk_ids'] or not state['summaries']:\n",
    "        print(\"⚠️ No chunks or valid summaries available. Skipping eligibility check.\")\n",
    "        logger.warning(\"⚠️ No chunks or valid summaries available. Skipping eligibility check.\")\n",
    "        for sid in state['summary_ids']:\n",
    "            for criterion in state['criteria_prompts']:\n",
    "                eligibility_results.append({\n",
    "                    \"summary_id\": sid,\n",
    "                    \"criteria_name\": criterion['Criteria_name'],\n",
    "                    \"trial_name\": criterion.get('Trial_Name', 'Unknown'),\n",
    "                    \"eligibility\": \"No\",\n",
    "                    \"evidence\": \"No chunks available\"\n",
    "                })\n",
    "        state['eligibility_results'] = eligibility_results\n",
    "        print(f\"✅ Generated {len(eligibility_results)} placeholder eligibility results.\")\n",
    "        logger.info(f\"✅ Generated {len(eligibility_results)} placeholder eligibility results.\")\n",
    "        return state\n",
    "    \n",
    "    for criterion in state['criteria_prompts']:\n",
    "        criteria_name = criterion['Criteria_name']\n",
    "        criteria_text = criterion['Text']\n",
    "        cot_steps = criterion['chainOfThought']\n",
    "        lexicons = criterion['extractableLexicons']\n",
    "        trial_name = criterion.get('Trial_Name', 'Unknown')\n",
    "        \n",
    "        state['embedding_function'].document_mode = False\n",
    "        try:\n",
    "            results = collection.query(\n",
    "                query_texts=[criteria_text.replace(\"\\n\", \" \")],\n",
    "                n_results=5,\n",
    "            )\n",
    "            relevant_chunks = results['documents'][0]\n",
    "            chunk_ids = results['ids'][0]\n",
    "            print(f\"Retrieved {len(relevant_chunks)} chunks for criterion '{criteria_name}'.\")\n",
    "            logger.info(f\"Retrieved {len(relevant_chunks)} chunks for criterion '{criteria_name}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error querying ChromaDB for '{criteria_name}': {e}\")\n",
    "            logger.error(f\"❌ Error querying ChromaDB for '{criteria_name}': {e}\")\n",
    "            for sid in state['summary_ids']:\n",
    "                eligibility_results.append({\n",
    "                    \"summary_id\": sid,\n",
    "                    \"criteria_name\": criteria_name,\n",
    "                    \"trial_name\": trial_name,\n",
    "                    \"eligibility\": \"No\",\n",
    "                    \"evidence\": f\"Error: {str(e)}\"\n",
    "                })\n",
    "            continue\n",
    "        \n",
    "        context = \"\\n\".join([f\"Chunk {i+1} (ID: {cid}): {chunk}\" for i, (chunk, cid) in enumerate(zip(relevant_chunks, chunk_ids))])\n",
    "        if not context:\n",
    "            context = \"No relevant chunks found.\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are a medical data analyst evaluating patient eligibility for a clinical trial based on the following criterion and retrieved clinical note chunks. Follow the chain-of-thought steps precisely and adhere to the output format.\n",
    "\n",
    "        Criterion:\n",
    "        - Name: {criteria_name}\n",
    "        - Description: {criteria_text}\n",
    "        - Extractable Lexicons: {json.dumps(lexicons)}\n",
    "        - Chain of Thought: {json.dumps(cot_steps)}\n",
    "\n",
    "        Retrieved Chunks:\n",
    "        {context}\n",
    "\n",
    "        Instructions:\n",
    "        - Do NOT infer conditions based on symptoms or medications.\n",
    "        - Only extract conditions pertinent to the patient (not their family).\n",
    "        - Evidence must have an exact match in the clinical note.\n",
    "        - Follow the chain-of-thought steps to determine eligibility.\n",
    "        - Return a JSON array with one object per patient summary, matching the summary IDs: {json.dumps(state['summary_ids'])}.\n",
    "        - Output format: {{\"summary_id\": \"ID\", \"Eligibility\": \"Yes\" or \"No\", \"Evidence\": \"Relevant text or None\"}}\n",
    "\n",
    "        Output a JSON array of eligibility results for each patient summary.\n",
    "        \"\"\"\n",
    "        \n",
    "        @retry(\n",
    "            wait=wait_random_exponential(min=1, max=10),\n",
    "            stop=stop_after_attempt(5),\n",
    "            retry=retry_if_exception_type((ResourceExhausted, InternalServerError, ServiceUnavailable, DeadlineExceeded))\n",
    "        )\n",
    "        def generate_eligibility():\n",
    "            try:\n",
    "                response = client.models.generate_content(\n",
    "                    model=\"gemini-1.5-flash\",\n",
    "                    contents=prompt,\n",
    "                    config=types.GenerateContentConfig()\n",
    "                )\n",
    "                response_text = response.candidates[0].content.parts[0].text\n",
    "                response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                results = json.loads(response_text)\n",
    "                return results\n",
    "            except Exception as e:\n",
    "                print(f\"Retrying due to error for '{criteria_name}': {e}\")\n",
    "                logger.error(f\"Retrying due to error for '{criteria_name}': {e}\")\n",
    "                raise\n",
    "        \n",
    "        try:\n",
    "            results = generate_eligibility()\n",
    "            result_map = {r[\"summary_id\"]: r for r in results if \"summary_id\" in r}\n",
    "            for sid in state['summary_ids']:\n",
    "                if sid in result_map:\n",
    "                    eligibility_results.append({\n",
    "                        \"summary_id\": sid,\n",
    "                        \"criteria_name\": criteria_name,\n",
    "                        \"trial_name\": trial_name,\n",
    "                        \"eligibility\": result_map[sid][\"Eligibility\"],\n",
    "                        \"evidence\": result_map[sid][\"Evidence\"]\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"⚠️ Missing result for summary ID {sid} in criterion '{criteria_name}'.\")\n",
    "                    logger.warning(f\"⚠️ Missing result for summary ID {sid} in criterion '{criteria_name}'.\")\n",
    "                    eligibility_results.append({\n",
    "                        \"summary_id\": sid,\n",
    "                        \"criteria_name\": criteria_name,\n",
    "                        \"trial_name\": trial_name,\n",
    "                        \"eligibility\": \"No\",\n",
    "                        \"evidence\": \"Missing API response\"\n",
    "                    })\n",
    "            print(f\"✅ Evaluated eligibility for '{criteria_name}': {len(result_map)} results.\")\n",
    "            logger.info(f\"✅ Evaluated eligibility for '{criteria_name}': {len(result_map)} results.\")\n",
    "            time.sleep(5)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to evaluate eligibility for '{criteria_name}' after retries: {e}\")\n",
    "            logger.error(f\"❌ Failed to evaluate eligibility for '{criteria_name}' after retries: {e}\")\n",
    "            for sid in state['summary_ids']:\n",
    "                eligibility_results.append({\n",
    "                    \"summary_id\": sid,\n",
    "                    \"criteria_name\": criteria_name,\n",
    "                    \"trial_name\": trial_name,\n",
    "                    \"eligibility\": \"No\",\n",
    "                    \"evidence\": f\"Error: {str(e)}\"\n",
    "                })\n",
    "        finally:\n",
    "            state['embedding_function'].document_mode = True\n",
    "    \n",
    "    state['eligibility_results'] = eligibility_results\n",
    "    print(f\"✅ Generated {len(eligibility_results)} eligibility results.\")\n",
    "    logger.info(f\"✅ Generated {len(eligibility_results)} eligibility results.\")\n",
    "    return state\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_results(state: PipelineState) -> PipelineState:\n",
    "    print(\"Starting evaluation step...\")\n",
    "    logger.info(\"Starting evaluation step...\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    try:\n",
    "        chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "        collection = chroma_client.get_collection(\n",
    "            name=\"mimic_iv_summary_chunks_trial\",\n",
    "            embedding_function=state['embedding_function']\n",
    "        )\n",
    "        print(f\"✅ ChromaDB collection loaded with {collection.count()} chunks.\")\n",
    "        logger.info(f\"✅ ChromaDB collection loaded with {collection.count()} chunks.\")\n",
    "    except (ValueError, InvalidCollectionException) as e:\n",
    "        print(f\"❌ Collection 'mimic_iv_summary_chunks_trial' does not exist: {e}\")\n",
    "        logger.error(f\"❌ Collection 'mimic_iv_summary_chunks_trial' does not exist: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading ChromaDB collection: {e}\")\n",
    "        logger.error(f\"❌ Error loading ChromaDB collection: {e}\")\n",
    "        raise\n",
    "    \n",
    "    evaluation_results = []\n",
    "    summary_map = dict(zip(state['summary_ids'], state['summaries']))\n",
    "    \n",
    "    criteria_groups = {}\n",
    "    for result in state['eligibility_results']:\n",
    "        crit_name = result['criteria_name']\n",
    "        if crit_name not in criteria_groups:\n",
    "            criteria_groups[crit_name] = []\n",
    "        criteria_groups[crit_name].append(result)\n",
    "    \n",
    "    for crit_name, results in criteria_groups.items():\n",
    "        print(f\"Processing criterion '{crit_name}'...\")\n",
    "        logger.info(f\"Processing criterion '{crit_name}'...\")\n",
    "        eval_results = []\n",
    "        trial_name = results[0]['trial_name']\n",
    "        \n",
    "        criterion = next((c for c in state['criteria_prompts'] if c['Criteria_name'] == crit_name), None)\n",
    "        if not criterion:\n",
    "            print(f\"❌ Criterion '{crit_name}' not found in criteria_prompts.\")\n",
    "            logger.error(f\"❌ Criterion '{crit_name}' not found in criteria_prompts.\")\n",
    "            continue\n",
    "        \n",
    "        query = criterion['Text']\n",
    "        query_oneline = query.replace(\"\\n\", \" \")\n",
    "        \n",
    "        for result in results:\n",
    "            patient_id = result['summary_id']\n",
    "            eligibility = result['eligibility']\n",
    "            raw_evidence = result['evidence']\n",
    "            patient_summary = summary_map.get(patient_id, \"Summary not found\")\n",
    "            \n",
    "            if isinstance(raw_evidence, list):\n",
    "                evidence_list = [e.strip() for e in raw_evidence if isinstance(e, str)]\n",
    "            elif isinstance(raw_evidence, str) and raw_evidence != \"None\":\n",
    "                evidence_list = [raw_evidence.strip()]\n",
    "            else:\n",
    "                evidence_list = []\n",
    "            \n",
    "            if eligibility == \"No\" and not evidence_list:\n",
    "                eval_results.append({\n",
    "                    \"Trial_Name\": trial_name,\n",
    "                    \"Criteria_Name\": crit_name,\n",
    "                    \"Patient_id\": patient_id,\n",
    "                    \"Eligibility\": eligibility,\n",
    "                    \"Evidence\": None,\n",
    "                    \"MatchedChunk\": None,\n",
    "                    \"Patient_Summary\": patient_summary,\n",
    "                    \"ROUGE-1\": None,\n",
    "                    \"ROUGE-2\": None,\n",
    "                    \"ROUGE-L\": None,\n",
    "                    \"fuzz_MatchScore\": None,\n",
    "                    \"CosineSimilarity\": None\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            state['embedding_function'].document_mode = False\n",
    "            matched_chunks = []\n",
    "            for ev in evidence_list:\n",
    "                try:\n",
    "                    query_result = collection.query(query_texts=[ev], n_results=1)\n",
    "                    top_chunk = query_result[\"documents\"][0][0] if query_result[\"documents\"] else \"\"\n",
    "                    matched_chunks.append(top_chunk)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Reverse RAG failed for evidence '{ev}' in '{crit_name}': {e}\")\n",
    "                    logger.warning(f\"⚠️ Reverse RAG failed for evidence '{ev}' in '{crit_name}': {e}\")\n",
    "                    matched_chunks.append(\"\")\n",
    "            state['embedding_function'].document_mode = True\n",
    "            \n",
    "            for ev, chunk in zip(evidence_list, matched_chunks):\n",
    "                try:\n",
    "                    state['embedding_function'].document_mode = False\n",
    "                    evidence_embedding = state['embedding_function']([ev])[0]\n",
    "                    state['embedding_function'].document_mode = True\n",
    "                    chunk_embedding = state['embedding_function']([chunk])[0]\n",
    "                    cos_sim = cosine_similarity([evidence_embedding], [chunk_embedding])[0][0]\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Cosine similarity failed for '{crit_name}': {e}\")\n",
    "                    logger.warning(f\"⚠️ Cosine similarity failed for '{crit_name}': {e}\")\n",
    "                    cos_sim = np.nan\n",
    "                \n",
    "                scores = scorer.score(ev, chunk)\n",
    "                eval_results.append({\n",
    "                    \"Trial_Name\": trial_name,\n",
    "                    \"Criteria_Name\": crit_name,\n",
    "                    \"Patient_id\": patient_id,\n",
    "                    \"Eligibility\": eligibility,\n",
    "                    \"Evidence\": ev,\n",
    "                    \"MatchedChunk\": chunk,\n",
    "                    \"Patient_Summary\": patient_summary,\n",
    "                    \"ROUGE-1\": round(scores[\"rouge1\"].fmeasure * 100, 2),\n",
    "                    \"ROUGE-2\": round(scores[\"rouge2\"].fmeasure * 100, 2),\n",
    "                    \"ROUGE-L\": round(scores[\"rougeL\"].fmeasure * 100, 2),\n",
    "                    \"fuzz_MatchScore\": round(fuzz.partial_ratio(ev, chunk), 2),\n",
    "                    \"CosineSimilarity\": round(cos_sim * 100, 2)\n",
    "                })\n",
    "        \n",
    "        output_dir = \"/kaggle/working/evaluation_results\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        df = pd.DataFrame(eval_results)\n",
    "        csv_path = os.path.join(output_dir, f\"{crit_name}_output_reverse_RAG_test.csv\")\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"✅ Saved: {csv_path}\")\n",
    "        logger.info(f\"✅ Saved: {csv_path}\")\n",
    "        \n",
    "        evaluation_results.extend(eval_results)\n",
    "    \n",
    "    consolidated_csv_path = \"/kaggle/working/evaluation_results/all_results.csv\"\n",
    "    consolidated_df = pd.DataFrame(evaluation_results)\n",
    "    consolidated_df.to_csv(consolidated_csv_path, index=False)\n",
    "    print(f\"✅ Saved consolidated results: {consolidated_csv_path}\")\n",
    "    logger.info(f\"✅ Saved consolidated results: {consolidated_csv_path}\")\n",
    "    \n",
    "    state['evaluation_results'] = evaluation_results\n",
    "    print(f\"✅ Generated {len(evaluation_results)} evaluation results.\")\n",
    "    logger.info(f\"✅ Generated {len(evaluation_results)} evaluation results.\")\n",
    "    return state\n",
    "\n",
    "# Build LangGraph Workflow\n",
    "def build_workflow() -> StateGraph:\n",
    "    print(\"Building LangGraph workflow...\")\n",
    "    logger.info(\"Building LangGraph workflow...\")\n",
    "    workflow = StateGraph(PipelineState)\n",
    "    workflow.add_node(\"summarization\", summarize_text)\n",
    "    workflow.add_node(\"database\", store_in_database)\n",
    "    workflow.add_node(\"criteria\", process_criteria)\n",
    "    workflow.add_node(\"chunking_embedding\", chunk_and_embed)\n",
    "    workflow.add_node(\"eligibility\", evaluate_eligibility)\n",
    "    workflow.add_node(\"evaluation\", evaluate_results)\n",
    "    workflow.set_entry_point(\"summarization\")\n",
    "    workflow.add_edge(\"summarization\", \"database\")\n",
    "    workflow.add_edge(\"database\", \"criteria\")\n",
    "    workflow.add_edge(\"criteria\", \"chunking_embedding\")\n",
    "    workflow.add_edge(\"chunking_embedding\", \"eligibility\")\n",
    "    workflow.add_edge(\"eligibility\", \"evaluation\")\n",
    "    workflow.add_edge(\"evaluation\", END)\n",
    "    print(\"✅ Workflow built with all nodes.\")\n",
    "    logger.info(\"✅ Workflow built with all nodes.\")\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "def run_pipeline(clinical_note, csv_file):\n",
    "    try:\n",
    "        raw_texts = []\n",
    "        if clinical_note and clinical_note.strip():\n",
    "            raw_texts.append(clinical_note.strip())\n",
    "        if csv_file is not None:\n",
    "            try:\n",
    "                df = pd.read_csv(csv_file.name)\n",
    "                if 'text' in df.columns:\n",
    "                    raw_texts.extend(df['text'].dropna().tolist())\n",
    "                else:\n",
    "                    yield {\n",
    "                        \"status\": \"Error: CSV must contain a 'text' column.\",\n",
    "                        \"log_output\": \"\"\n",
    "                    }\n",
    "                    return\n",
    "            except Exception as e:\n",
    "                yield {\n",
    "                    \"status\": f\"Error reading CSV: {str(e)}\",\n",
    "                    \"log_output\": \"\"\n",
    "                }\n",
    "                return\n",
    "        \n",
    "        if not raw_texts:\n",
    "            yield {\n",
    "                \"status\": \"Error: Please provide a clinical note or upload a valid CSV.\",\n",
    "                \"log_output\": \"\"\n",
    "            }\n",
    "            return\n",
    "        \n",
    "        log_buffer.truncate(0)\n",
    "        log_buffer.seek(0)\n",
    "        with redirect_stdout(log_buffer):\n",
    "            workflow = build_workflow()\n",
    "            initial_state = {\"raw_text\": raw_texts}\n",
    "            \n",
    "            steps = [\n",
    "                (\"Summarizing...\", summarize_text),\n",
    "                (\"Storing in database...\", store_in_database),\n",
    "                (\"Processing criteria...\", process_criteria),\n",
    "                (\"Chunking and embedding...\", chunk_and_embed),\n",
    "                (\"Evaluating eligibility...\", evaluate_eligibility),\n",
    "                (\"Evaluating results...\", evaluate_results)\n",
    "            ]\n",
    "            \n",
    "            state = initial_state\n",
    "            for step_name, step_func in steps:\n",
    "                yield {\n",
    "                    \"status\": step_name,\n",
    "                    \"log_output\": log_buffer.getvalue(),\n",
    "                    \"summary_output\": None,\n",
    "                    \"eligibility_output\": None,\n",
    "                    \"evaluation_output\": None,\n",
    "                    \"db_output\": None,\n",
    "                    \"chroma_output\": None,\n",
    "                    \"consolidated_csv\": None\n",
    "                }\n",
    "                state = step_func(state)\n",
    "                sys.stdout.flush()\n",
    "            \n",
    "            result = state\n",
    "            \n",
    "            summary_df = pd.DataFrame({\n",
    "                \"Summary_ID\": result['summary_ids'],\n",
    "                \"Original_Text\": [t[:200] + \"...\" for t in result['raw_text'][:len(result['summary_ids'])]],\n",
    "                \"Summary\": [s[:200] + \"...\" for s in result['summaries'] + [\"\"] * (len(result['summary_ids']) - len(result['summaries']))]\n",
    "            })\n",
    "            \n",
    "            eligibility_df = pd.DataFrame(result['eligibility_results'])\n",
    "            evaluation_df = pd.DataFrame(result['evaluation_results'])\n",
    "            \n",
    "            db_output = []\n",
    "            try:\n",
    "                with sqlite3.connect(\"/kaggle/working/clinical_data.db\") as conn:\n",
    "                    cursor = conn.cursor()\n",
    "                    cursor.execute(\"SELECT id, original_text, summary FROM summaries\")\n",
    "                    rows = cursor.fetchall()\n",
    "                    db_output = [{\"ID\": r[0], \"Original_Text\": r[1][:100] + \"...\", \"Summary\": r[2][:100] + \"...\"} for r in rows]\n",
    "            except Exception as e:\n",
    "                db_output = [{\"ID\": \"Error\", \"Original_Text\": str(e), \"Summary\": \"\"}]\n",
    "            \n",
    "            chroma_output = []\n",
    "            try:\n",
    "                chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "                collection = chroma_client.get_collection(name=\"mimic_iv_summary_chunks_trial\")\n",
    "                count = collection.count()\n",
    "                results = collection.peek(limit=5)\n",
    "                chroma_output = [{\"Chunk_ID\": cid, \"Document\": doc[:100] + \"...\"} for cid, doc in zip(results['ids'], results['documents'])]\n",
    "                chroma_output.insert(0, {\"Chunk_ID\": \"Total Count\", \"Document\": str(count)})\n",
    "            except Exception as e:\n",
    "                chroma_output = [{\"Chunk_ID\": \"Error\", \"Document\": str(e)}]\n",
    "            \n",
    "            consolidated_csv = \"/kaggle/working/evaluation_results/all_results.csv\"\n",
    "            status = f\"Pipeline completed: {len(result['summaries'])} summaries, {len(result['chunk_ids'])} chunks, {len(result['eligibility_results'])} eligibility results, {len(result['evaluation_results'])} evaluation results.\"\n",
    "            \n",
    "            yield {\n",
    "                \"status\": status,\n",
    "                \"summary_output\": summary_df,\n",
    "                \"eligibility_output\": eligibility_df,\n",
    "                \"evaluation_output\": evaluation_df,\n",
    "                \"db_output\": pd.DataFrame(db_output),\n",
    "                \"chroma_output\": pd.DataFrame(chroma_output),\n",
    "                \"consolidated_csv\": consolidated_csv,\n",
    "                \"log_output\": log_buffer.getvalue()\n",
    "            }\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error running pipeline: {str(e)}\"\n",
    "        yield {\n",
    "            \"status\": error_msg,\n",
    "            \"log_output\": log_buffer.getvalue() + \"\\n\" + error_msg,\n",
    "            \"summary_output\": None,\n",
    "            \"eligibility_output\": None,\n",
    "            \"evaluation_output\": None,\n",
    "            \"db_output\": None,\n",
    "            \"chroma_output\": None,\n",
    "            \"consolidated_csv\": None\n",
    "        }\n",
    "\n",
    "# # Gradio UI Functions\n",
    "# def run_pipeline(clinical_note, csv_file):\n",
    "#     try:\n",
    "#         raw_texts = []\n",
    "        # if clinical_note and clinical_note.strip():\n",
    "        #     raw_texts.append(clinical_note.strip())\n",
    "        # if csv_file is not None:\n",
    "        #     try:\n",
    "        #         df = pd.read_csv(csv_file.name)\n",
    "        #         if 'text' in df.columns:\n",
    "        #             raw_texts.extend(df['text'].dropna().tolist())\n",
    "        #         else:\n",
    "        #             yield {\"status\": \"Error: CSV must contain a 'text' column.\", \"logs\": \"\"}\n",
    "        #             return\n",
    "        #     except Exception as e:\n",
    "        #         yield {\"status\": f\"Error reading CSV: {str(e)}\", \"logs\": \"\"}\n",
    "        #         return\n",
    "        \n",
    "        # if not raw_texts:\n",
    "        #     yield {\"status\": \"Error: Please provide a clinical note or upload a valid CSV.\", \"logs\": \"\"}\n",
    "        #     return\n",
    "        \n",
    "        # log_buffer.truncate(0)\n",
    "        # log_buffer.seek(0)\n",
    "        # with redirect_stdout(log_buffer):\n",
    "        #     workflow = build_workflow()\n",
    "        #     initial_state = {\"raw_text\": raw_texts}\n",
    "            \n",
    "        #     # Simulate pipeline steps with progress updates\n",
    "        #     steps = [\n",
    "        #         (\"Summarizing...\", summarize_text),\n",
    "        #         (\"Storing in database...\", store_in_database),\n",
    "        #         (\"Processing criteria...\", process_criteria),\n",
    "        #         (\"Chunking and embedding...\", chunk_and_embed),\n",
    "        #         (\"Evaluating eligibility...\", evaluate_eligibility),\n",
    "        #         (\"Evaluating results...\", evaluate_results)\n",
    "        #     ]\n",
    "            \n",
    "        #     state = initial_state\n",
    "        #     for step_name, step_func in steps:\n",
    "        #         yield {\n",
    "            #         \"status\": step_name,\n",
    "            #         \"logs\": log_buffer.getvalue()\n",
    "            #     }\n",
    "            #     if step_func != summarize_text:  # Apply step_func directly for non-summarization steps\n",
    "            #         state = step_func(state)\n",
    "            #     else:\n",
    "            #         state = step_func(state)  # summarization step\n",
    "            #     sys.stdout.flush()\n",
    "            \n",
    "            # result = state  # Final state after all steps\n",
    "            \n",
    "            # # Format results for UI\n",
    "            # summary_df = pd.DataFrame({\n",
    "            #     \"Summary_ID\": result['summary_ids'],\n",
    "            #     \"Original_Text\": [t[:200] + \"...\" for t in result['raw_text'][:len(result['summary_ids'])]],\n",
    "            #     \"Summary\": [s[:200] + \"...\" for s in result['summaries'] + [\"\"] * (len(result['summary_ids']) - len(result['summaries']))]\n",
    "            # })\n",
    "            \n",
    "            # eligibility_df = pd.DataFrame(result['eligibility_results'])\n",
    "            # evaluation_df = pd.DataFrame(result['evaluation_results'])\n",
    "            \n",
    "            # # Database contents\n",
    "            # db_output = []\n",
    "            # try:\n",
    "            #     with sqlite3.connect(\"/kaggle/working/clinical_data.db\") as conn:\n",
    "            #         cursor = conn.cursor()\n",
    "            #         cursor.execute(\"SELECT id, original_text, summary FROM summaries\")\n",
    "            #         rows = cursor.fetchall()\n",
    "            #         db_output = [{\"ID\": r[0], \"Original_Text\": r[1][:100] + \"...\", \"Summary\": r[2][:100] + \"...\"} for r in rows]\n",
    "            # except Exception as e:\n",
    "            #     db_output = [{\"ID\": \"Error\", \"Original_Text\": str(e), \"Summary\": \"\"}]\n",
    "            \n",
    "            # # ChromaDB contents\n",
    "            # chroma_output = []\n",
    "            # try:\n",
    "            #     chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "            #     collection = chroma_client.get_collection(name=\"mimic_iv_summary_chunks_trial\")\n",
    "            #     count = collection.count()\n",
    "            #     results = collection.peek(limit=5)\n",
    "            #     chroma_output = [{\"Chunk_ID\": cid, \"Document\": doc[:100] + \"...\"} for cid, doc in zip(results['ids'], results['documents'])]\n",
    "            #     chroma_output.insert(0, {\"Chunk_ID\": \"Total Count\", \"Document\": str(count)})\n",
    "            # except Exception as e:\n",
    "            #     chroma_output = [{\"Chunk_ID\": \"Error\", \"Document\": str(e)}]\n",
    "            \n",
    "            # consolidated_csv = \"/kaggle/working/evaluation_results/all_results.csv\"\n",
    "            # status = f\"Pipeline completed: {len(result['summaries'])} summaries, {len(result['chunk_ids'])} chunks, {len(result['eligibility_results'])} eligibility results, {len(result['evaluation_results'])} evaluation results.\"\n",
    "            \n",
    "    #         yield {\n",
    "    #             \"status\": status,\n",
    "    #             \"summary_df\": summary_df,\n",
    "    #             \"eligibility_df\": eligibility_df,\n",
    "    #             \"evaluation_df\": evaluation_df,\n",
    "    #             \"db_df\": pd.DataFrame(db_output),\n",
    "    #             \"chroma_df\": pd.DataFrame(chroma_output),\n",
    "    #             \"consolidated_csv\": consolidated_csv,\n",
    "    #             \"logs\": log_buffer.getvalue()\n",
    "    #         }\n",
    "    \n",
    "    # except Exception as e:\n",
    "    #     error_msg = f\"Error running pipeline: {str(e)}\"\n",
    "    #     yield {\n",
    "    #         \"status\": error_msg,\n",
    "    #         \"logs\": log_buffer.getvalue() + \"\\n\" + error_msg\n",
    "    #     }\n",
    "\n",
    "def clear_outputs():\n",
    "    try:\n",
    "        shutil.rmtree(\"/kaggle/working/chromadb\", ignore_errors=True)\n",
    "        shutil.rmtree(\"/kaggle/working/evaluation_results\", ignore_errors=True)\n",
    "        shutil.rmtree(\"/kaggle/working/Criteria_based_Prompts\", ignore_errors=True)\n",
    "        if os.path.exists(\"/kaggle/working/clinical_data.db\"):\n",
    "            os.remove(\"/kaggle/working/clinical_data.db\")\n",
    "        if os.path.exists(\"/kaggle/working/pipeline.log\"):\n",
    "            os.remove(\"/kaggle/working/pipeline.log\")\n",
    "        return \"Output directories, database, and log file cleared successfully!\"\n",
    "    except Exception as e:\n",
    "        return f\"Error clearing outputs: {str(e)}\"\n",
    "\n",
    "# Main execution (preserved as original)\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading test data...\")\n",
    "    logger.info(\"Loading test data...\")\n",
    "    try:\n",
    "        df = pd.read_csv('/kaggle/input/mimic-iv-2/mimic_iv_summarization_test_dataset_shortened_edited.csv', nrows=10)\n",
    "        df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "        print(f\"Test data loaded: {len(df_test)} samples.\")\n",
    "        logger.info(f\"Test data loaded: {len(df_test)} samples.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading test data: {e}\")\n",
    "        logger.error(f\"Error loading test data: {e}\")\n",
    "        raise\n",
    "    \n",
    "    print(\"Running LangGraph pipeline...\")\n",
    "    logger.info(\"Running LangGraph pipeline...\")\n",
    "    workflow = build_workflow()\n",
    "    initial_state = {\"raw_text\": df_test['text'].tolist()}\n",
    "    result = workflow.invoke(initial_state)\n",
    "    \n",
    "    print(\"\\nPipeline Result:\")\n",
    "    logger.info(\"\\nPipeline Result:\")\n",
    "    print(f\"Input Texts: {len(result['raw_text'])}\")\n",
    "    logger.info(f\"Input Texts: {len(result['raw_text'])}\")\n",
    "    print(f\"Summaries: {len(result['summaries'])}\")\n",
    "    logger.info(f\"Summaries: {len(result['summaries'])}\")\n",
    "    print(f\"Summary IDs: {len(result['summary_ids'])}\")\n",
    "    logger.info(f\"Summary IDs: {len(result['summary_ids'])}\")\n",
    "    print(f\"Criteria Prompts: {len(result['criteria_prompts'])}\")\n",
    "    logger.info(f\"Criteria Prompts: {len(result['criteria_prompts'])}\")\n",
    "    print(f\"Chunk IDs: {len(result['chunk_ids'])}\")\n",
    "    logger.info(f\"Chunk IDs: {len(result['chunk_ids'])}\")\n",
    "    print(f\"Eligibility Results: {len(result['eligibility_results'])}\")\n",
    "    logger.info(f\"Eligibility Results: {len(result['eligibility_results'])}\")\n",
    "    print(f\"Evaluation Results: {len(result['evaluation_results'])}\")\n",
    "    logger.info(f\"Evaluation Results: {len(result['evaluation_results'])}\")\n",
    "\n",
    "    \n",
    "    for i, (text, summary, sid) in enumerate(zip(result['raw_text'], result['summaries'] + [\"\"] * (len(result['raw_text']) - len(result['summaries'])), result['summary_ids'])):\n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        logger.info(f\"\\nSample {i+1}:\")\n",
    "        print(f\"Input (first 100 chars): {text[:100]}...\")\n",
    "        logger.info(f\"Input (first 100 chars): {text[:100]}...\")\n",
    "        print(f\"Summary (first 200 chars): {summary[:200]}...\")\n",
    "        logger.info(f\"Summary (first 200 chars): {summary[:200]}...\")\n",
    "        print(f\"Summary ID: {sid}\")\n",
    "        logger.info(f\"Summary ID: {sid}\")\n",
    "        if \"(error\" in summary.lower():\n",
    "            print(f\"Error detected in summary: {summary}\")\n",
    "            logger.error(f\"Error detected in summary: {summary}\")\n",
    "    \n",
    "    print(\"\\nSample Criteria Prompts:\")\n",
    "    logger.info(\"\\nSample Criteria Prompts:\")\n",
    "    for i, prompt in enumerate(result['criteria_prompts'][:2]):\n",
    "        print(f\"Prompt {i+1}:\")\n",
    "        logger.info(f\"Prompt {i+1}:\")\n",
    "        print(f\"Trial Name: {prompt.get('Trial_Name', 'Unknown')}\")\n",
    "        logger.info(f\"Trial Name: {prompt.get('Trial_Name', 'Unknown')}\")\n",
    "        print(f\"Criteria Name: {prompt['Criteria_name']}\")\n",
    "        logger.info(f\"Criteria Name: {prompt['Criteria_name']}\")\n",
    "        print(f\"Text: {prompt['Text']}\")\n",
    "        logger.info(f\"Text: {prompt['Text']}\")\n",
    "        print(f\"Extractable Lexicons: {prompt['extractableLexicons']}\")\n",
    "        logger.info(f\"Extractable Lexicons: {prompt['extractableLexicons']}\")\n",
    "    \n",
    "    print(\"\\nSample Chunks:\")\n",
    "    logger.info(\"\\nSample Chunks:\")\n",
    "    for i, cid in enumerate(result['chunk_ids'][:2]):\n",
    "        print(f\"Chunk ID: {cid}\")\n",
    "        logger.info(f\"Chunk ID: {cid}\")\n",
    "    \n",
    "    print(\"\\nSample Eligibility Results:\")\n",
    "    logger.info(\"\\nSample Eligibility Results:\")\n",
    "    for i, res in enumerate(result['eligibility_results'][:4]):\n",
    "        print(f\"Result {i+1}:\")\n",
    "        logger.info(f\"Result {i+1}:\")\n",
    "        print(f\"Trial Name: {res['trial_name']}\")\n",
    "        logger.info(f\"Trial Name: {res['trial_name']}\")\n",
    "        print(f\"Summary ID: {res['summary_id']}\")\n",
    "        logger.info(f\"Summary ID: {res['summary_id']}\")\n",
    "        print(f\"Criteria Name: {res['criteria_name']}\")\n",
    "        logger.info(f\"Criteria Name: {res['criteria_name']}\")\n",
    "        print(f\"Eligibility: {res['eligibility']}\")\n",
    "        logger.info(f\"Eligibility: {res['eligibility']}\")\n",
    "        print(f\"Evidence: {res['evidence']}\")\n",
    "        logger.info(f\"Evidence: {res['evidence']}\")\n",
    "    \n",
    "    print(\"\\nSample Evaluation Results:\")\n",
    "    logger.info(\"\\nSample Evaluation Results:\")\n",
    "    for i, res in enumerate(result['evaluation_results'][:4]):\n",
    "        print(f\"Result {i+1}:\")\n",
    "        logger.info(f\"Result {i+1}:\")\n",
    "        print(f\"Trial Name: {res['Trial_Name']}\")\n",
    "        logger.info(f\"Trial Name: {res['Trial_Name']}\")\n",
    "        print(f\"Patient ID: {res['Patient_id']}\")\n",
    "        logger.info(f\"Patient ID: {res['Patient_id']}\")\n",
    "        print(f\"Criteria Name: {res['Criteria_Name']}\")\n",
    "        logger.info(f\"Criteria Name: {res['Criteria_Name']}\")\n",
    "        print(f\"Eligibility: {res['Eligibility']}\")\n",
    "        logger.info(f\"Eligibility: {res['Eligibility']}\")\n",
    "        print(f\"Evidence: {res['Evidence']}\")\n",
    "        logger.info(f\"Evidence: {res['Evidence']}\")\n",
    "        print(f\"ROUGE-1: {res['ROUGE-1']}\")\n",
    "        logger.info(f\"ROUGE-1: {res['ROUGE-1']}\")\n",
    "        print(f\"fuzz_MatchScore: {res['fuzz_MatchScore']}\")\n",
    "        logger.info(f\"fuzz_MatchScore: {res['fuzz_MatchScore']}\")\n",
    "    \n",
    "    print(\"\\nVerifying database contents...\")\n",
    "    logger.info(\"\\nVerifying database contents...\")\n",
    "    try:\n",
    "        with sqlite3.connect(\"/kaggle/working/clinical_data.db\") as conn:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"SELECT id, original_text, summary FROM summaries\")\n",
    "            rows = cursor.fetchall()\n",
    "            print(f\"Found {len(rows)} records in database.\")\n",
    "            logger.info(f\"Found {len(rows)} records in database.\")\n",
    "            for row in rows[:2]:\n",
    "                print(f\"Record ID: {row[0]}, Original Text (first 50 chars): {row[1][:50]}..., Summary (first 50 chars): {row[2][:50]}...\")\n",
    "                logger.info(f\"Record ID: {row[0]}, Original Text (first 50 chars): {row[1][:50]}..., Summary (first 50 chars): {row[2][:50]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error verifying database: {e}\")\n",
    "        logger.error(f\"Error verifying database: {e}\")\n",
    "    \n",
    "    print(\"\\nVerifying ChromaDB contents...\")\n",
    "    logger.info(\"\\nVerifying ChromaDB contents...\")\n",
    "    try:\n",
    "        chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "        collection = chroma_client.get_collection(name=\"mimic_iv_summary_chunks_trial\")\n",
    "        count = collection.count()\n",
    "        print(f\"Found {count} chunks in ChromaDB collection 'mimic_iv_summary_chunks_trial'.\")\n",
    "        logger.info(f\"Found {count} chunks in ChromaDB collection 'mimic_iv_summary_chunks_trial'.\")\n",
    "        results = collection.peek(limit=2)\n",
    "        for i, (doc, cid) in enumerate(zip(results['documents'], results['ids'])):\n",
    "            print(f\"Chunk {i+1} (ID: {cid}): {doc[:100]}...\")\n",
    "            logger.info(f\"Chunk {i+1} (ID: {cid}): {doc[:100]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error verifying ChromaDB: {e}\")\n",
    "        logger.error(f\"Error verifying ChromaDB: {e}\")\n",
    "    \n",
    "    print(\"\\nVerifying CSV outputs...\")\n",
    "    logger.info(\"\\nVerifying CSV outputs...\")\n",
    "    try:\n",
    "        csv_files = glob.glob(\"/kaggle/working/evaluation_results/*_output_reverse_RAG_test.csv\")\n",
    "        print(f\"Found {len(csv_files)} CSV files in /kaggle/working/evaluation_results/\")\n",
    "        logger.info(f\"Found {len(csv_files)} CSV files in /kaggle/working/evaluation_results/\")\n",
    "        for csv_file in csv_files[:2]:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            print(f\"\\nCSV: {csv_file}\")\n",
    "            logger.info(f\"\\nCSV: {csv_file}\")\n",
    "            print(df.head(2).to_string())\n",
    "            logger.info(df.head(2).to_string())\n",
    "    except Exception as e:\n",
    "        print(f\"Error verifying CSV outputs: {e}\")\n",
    "        logger.error(f\"Error verifying CSV outputs: {e}\")\n",
    "\n",
    "# Gradio Interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Clinical Trial Pipeline\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            clinical_note = gr.Textbox(label=\"Clinical Note\", placeholder=\"Enter a clinical discharge note...\")\n",
    "            csv_file = gr.File(label=\"Upload CSV (with 'text' column)\")\n",
    "            with gr.Row():\n",
    "                run_button = gr.Button(\"Run Pipeline\")\n",
    "                clear_button = gr.Button(\"Clear Outputs\")\n",
    "        with gr.Column():\n",
    "            status = gr.Textbox(label=\"Status\", value=\"Ready to run pipeline.\")\n",
    "    \n",
    "    with gr.Tabs():\n",
    "        with gr.Tab(\"Summaries\"):\n",
    "            summary_output = gr.DataFrame(label=\"Summaries\")\n",
    "        with gr.Tab(\"Eligibility Results\"):\n",
    "            eligibility_output = gr.DataFrame(label=\"Eligibility Results\")\n",
    "        with gr.Tab(\"Evaluation Results\"):\n",
    "            evaluation_output = gr.DataFrame(label=\"Evaluation Results\")\n",
    "        with gr.Tab(\"Database Contents\"):\n",
    "            db_output = gr.DataFrame(label=\"Database Contents\")\n",
    "        with gr.Tab(\"ChromaDB Contents\"):\n",
    "            chroma_output = gr.DataFrame(label=\"ChromaDB Contents\")\n",
    "        with gr.Tab(\"Logs\"):\n",
    "            log_output = gr.Textbox(label=\"Logs\", lines=20)\n",
    "    \n",
    "    consolidated_csv = gr.File(label=\"Download Consolidated Results\")\n",
    "\n",
    "\n",
    "    def update_outputs(clinical_note, csv_file):\n",
    "        # Default values for all output components\n",
    "        default_output = {\n",
    "            \"status\": \"Initializing...\",\n",
    "            \"summary_output\": None,\n",
    "            \"eligibility_output\": None,\n",
    "            \"evaluation_output\": None,\n",
    "            \"db_output\": None,\n",
    "            \"chroma_output\": None,\n",
    "            \"consolidated_csv\": None,\n",
    "            \"log_output\": \"\"\n",
    "        }\n",
    "        \n",
    "        for output in run_pipeline(clinical_note, csv_file):\n",
    "            # Ensure the output dictionary only contains expected keys\n",
    "            current_output = default_output.copy()\n",
    "            current_output.update({k: v for k, v in output.items() if k in default_output})\n",
    "            \n",
    "            # Yield a tuple with exactly 8 values, one for each output component\n",
    "            yield (\n",
    "                current_output[\"status\"],\n",
    "                current_output[\"summary_output\"],\n",
    "                current_output[\"eligibility_output\"],\n",
    "                current_output[\"evaluation_output\"],\n",
    "                current_output[\"db_output\"],\n",
    "                current_output[\"chroma_output\"],\n",
    "                current_output[\"consolidated_csv\"],\n",
    "                current_output[\"log_output\"]\n",
    "            )\n",
    "\n",
    "    # def update_outputs(clinical_note, csv_file):\n",
    "    #     # Default output dictionary with all required keys\n",
    "    #     default_output = {\n",
    "    #         \"status\": \"Initializing...\",\n",
    "    #         \"summary_output\": None,\n",
    "    #         \"eligibility_output\": None,\n",
    "    #         \"evaluation_output\": None,\n",
    "    #         \"db_output\": None,\n",
    "    #         \"chroma_output\": None,\n",
    "    #         \"consolidated_csv\": None,\n",
    "    #         \"log_output\": \"\"\n",
    "    #     }\n",
    "        \n",
    "    #     for output in run_pipeline(clinical_note, csv_file):\n",
    "    #         # Merge the yielded output with the default output to ensure all keys are present\n",
    "    #         current_output = default_output.copy()\n",
    "    #         current_output.update(output)\n",
    "    #         yield current_output\n",
    "    \n",
    "    # def update_outputs(clinical_note, csv_file):\n",
    "    #     for output in run_pipeline(clinical_note, csv_file):\n",
    "    #         yield {\n",
    "    #             \"status\": output.get(\"status\", \"\"),\n",
    "    #             \"summary_output\": output.get(\"summary_df\", None),\n",
    "    #             \"eligibility_output\": output.get(\"eligibility_df\", None),\n",
    "    #             \"evaluation_output\": output.get(\"evaluation_df\", None),\n",
    "    #             \"db_output\": output.get(\"db_df\", None),\n",
    "    #             \"chroma_output\": output.get(\"chroma_df\", None),\n",
    "    #             \"consolidated_csv\": output.get(\"consolidated_csv\", None),\n",
    "    #             \"log_output\": output.get(\"logs\", \"\")\n",
    "    #         }\n",
    "    \n",
    "    run_button.click(\n",
    "        fn=update_outputs,\n",
    "        inputs=[clinical_note, csv_file],\n",
    "        outputs=[\n",
    "            status,\n",
    "            summary_output,\n",
    "            eligibility_output,\n",
    "            evaluation_output,\n",
    "            db_output,\n",
    "            chroma_output,\n",
    "            consolidated_csv,\n",
    "            log_output\n",
    "        ]\n",
    "    )\n",
    "    clear_button.click(\n",
    "        fn=clear_outputs,\n",
    "        inputs=None,\n",
    "        outputs=status\n",
    "    )\n",
    "\n",
    "# Launch Gradio in Kaggle\n",
    "try:\n",
    "    demo.launch(\n",
    "        server_name=\"0.0.0.0\",\n",
    "        server_port=7860,\n",
    "        inline=True,\n",
    "        quiet=False\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error launching Gradio: {e}\")\n",
    "    print(\"Please ensure the notebook is public and try running the cell again.\")\n",
    "    print(\"Alternatively, check the Kaggle output cell below for the Gradio URL.\")\n",
    "    logger.error(f\"Error launching Gradio: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T19:15:44.685314Z",
     "iopub.status.busy": "2025-04-20T19:15:44.685025Z",
     "iopub.status.idle": "2025-04-20T19:15:44.689500Z",
     "shell.execute_reply": "2025-04-20T19:15:44.688695Z",
     "shell.execute_reply.started": "2025-04-20T19:15:44.685291Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CHROMA_DB_PATH = '/kaggle/working/chromadb_2_sample_v15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "day-2-document-q-a-with-rag.ipynb",
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7201341,
     "sourceId": 11488767,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7202392,
     "sourceId": 11490099,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
